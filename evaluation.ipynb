{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fMRI-to-Image Reconstruction Evaluation\n",
    "\n",
    "Comprehensive evaluation suite for fMRI reconstruction quality using multiple metrics.\n",
    "\n",
    "## Available Metrics\n",
    "\n",
    "### **Working Metrics**\n",
    "- **AlexNet-2/5**: Feature similarity analysis\n",
    "- **InceptionV3**: High-level feature similarity\n",
    "- **EfficientNet-B1**: Distance metrics\n",
    "\n",
    "### **Requires Ground Truth**\n",
    "- **SSIM**: Structural similarity\n",
    "- **PixCorr**: Pixel correlation\n",
    "- **Two-way identification**: AlexNet, CLIP, InceptionV3\n",
    "\n",
    "### **Requires Additional Data**\n",
    "- **Brain correlations**: GNet model + fMRI data\n",
    "- **Retrieval metrics**: Candidate datasets\n",
    "- **Image quality**: IS, FID\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "**Modify these variables to customize your evaluation:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstruction directory: /home/kevin/Documents/ACV/Project/advanced-cv-project/outputs_all/subj01/cp_4096_v1/300000/0.2/ground_truth\n",
      "Ground truth directory: /home/kevin/Documents/ACV/Project/advanced-cv-project/outputs_all/subj01/cp_4096_v1/300000/0.2/with_z\n",
      "fMRI data directory: /home/kevin/Documents/ACV/Project/advanced-cv-project/MindEyeV2\n",
      "Images to evaluate: 50\n",
      "Batch size: 8\n",
      "Device: cuda\n",
      "Has ground truth: True\n",
      "Has fMRI data: True\n",
      "Has GNet model: False\n",
      "Reconstruction directory: /home/kevin/Documents/ACV/Project/advanced-cv-project/outputs_all/subj01/cp_4096_v1/300000/0.2/ground_truth\n",
      "Ground truth directory: /home/kevin/Documents/ACV/Project/advanced-cv-project/outputs_all/subj01/cp_4096_v1/300000/0.2/with_z\n",
      "fMRI data directory: /home/kevin/Documents/ACV/Project/advanced-cv-project/MindEyeV2\n",
      "Images to evaluate: 50\n",
      "Batch size: 8\n",
      "Device: cuda\n",
      "Has ground truth: True\n",
      "Has fMRI data: True\n",
      "Has GNet model: False\n"
     ]
    }
   ],
   "source": [
    "# ===== EVALUATION CONFIGURATION =====\n",
    "# Modify these variables to customize your evaluation\n",
    "\n",
    "# Paths\n",
    "PROJECT_ROOT = '/home/kevin/Documents/ACV/Project/advanced-cv-project'\n",
    "RECON_DIR = f'{PROJECT_ROOT}/outputs_all/subj01/cp_4096_v1/300000/0.2/ground_truth'\n",
    "GT_DIR = f'{PROJECT_ROOT}/outputs_all/subj01/cp_4096_v1/300000/0.2/with_z'  # Ground truth images\n",
    "FMRI_DIR = f'{PROJECT_ROOT}/MindEyeV2'  # fMRI data (if available)\n",
    "\n",
    "# Evaluation parameters\n",
    "NUM_IMAGES_TO_EVALUATE = 50  # Number of images to evaluate\n",
    "BATCH_SIZE = 8  # Batch size for processing (reduce if GPU memory issues)\n",
    "DEVICE = 'cuda'  # 'cuda' or 'cpu'\n",
    "\n",
    "# Data availability flags\n",
    "HAS_GROUND_TRUTH = True  # Set to True if you have ground truth images\n",
    "HAS_FMRI_DATA = True     # Set to True if you have fMRI data\n",
    "HAS_GNET_MODEL = False    # Set to True if you have GNet model\n",
    "\n",
    "print(f\"Reconstruction directory: {RECON_DIR}\")\n",
    "print(f\"Ground truth directory: {GT_DIR}\")\n",
    "print(f\"fMRI data directory: {FMRI_DIR}\")\n",
    "print(f\"Images to evaluate: {NUM_IMAGES_TO_EVALUATE}\")\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "print(f\"Device: {DEVICE}\")\n",
    "print(f\"Has ground truth: {HAS_GROUND_TRUTH}\")\n",
    "print(f\"Has fMRI data: {HAS_FMRI_DATA}\")\n",
    "print(f\"Has GNet model: {HAS_GNET_MODEL}\")\n",
    "\n",
    "# Data availability flags\n",
    "HAS_GROUND_TRUTH = True  # Set to True if you have ground truth images\n",
    "HAS_FMRI_DATA = True     # Set to True if you have fMRI data\n",
    "HAS_GNET_MODEL = False    # Set to True if you have GNet model\n",
    "\n",
    "print(f\"Reconstruction directory: {RECON_DIR}\")\n",
    "print(f\"Ground truth directory: {GT_DIR}\")\n",
    "print(f\"fMRI data directory: {FMRI_DIR}\")\n",
    "print(f\"Images to evaluate: {NUM_IMAGES_TO_EVALUATE}\")\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "print(f\"Device: {DEVICE}\")\n",
    "print(f\"Has ground truth: {HAS_GROUND_TRUTH}\")\n",
    "print(f\"Has fMRI data: {HAS_FMRI_DATA}\")\n",
    "print(f\"Has GNet model: {HAS_GNET_MODEL}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU: NVIDIA GeForce RTX 5070 Ti\n",
      "Memory: 16.60 GB\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add project to path\n",
    "sys.path.insert(0, PROJECT_ROOT)\n",
    "\n",
    "# Check GPU availability\n",
    "device = torch.device(DEVICE if torch.cuda.is_available() and DEVICE == 'cuda' else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All evaluation metrics imported successfully!\n",
      "Available metrics:\n",
      "  - Low-level: SSIM, PixCorr\n",
      "  - High-level: AlexNet, CLIP, InceptionV3\n",
      "  - Distance: EfficientNet, SwAV\n",
      "  - Brain correlation: GNet-based correlations\n",
      "  - Retrieval: Image and Brain retrieval\n",
      "  - Image quality: IS, FID\n"
     ]
    }
   ],
   "source": [
    "# Import evaluation metrics\n",
    "from evaluation.orchestrator import EvaluationOrchestrator\n",
    "from evaluation.low_level import SSIM, PixCorr\n",
    "from evaluation.high_level import AlexNetMetrics, CLIPMetrics, InceptionMetrics\n",
    "from evaluation.distance import EfficientNetDistance, SwAVDistance\n",
    "from evaluation.brain_correlation import BrainCorrelationMetrics\n",
    "from evaluation.retrieval import ImageRetrieval, BrainRetrieval\n",
    "from evaluation.image_quality import InceptionScore, FID\n",
    "\n",
    "print(\"All evaluation metrics imported successfully!\")\n",
    "print(\"Available metrics:\")\n",
    "print(\"  - Low-level: SSIM, PixCorr\")\n",
    "print(\"  - High-level: AlexNet, CLIP, InceptionV3\")\n",
    "print(\"  - Distance: EfficientNet, SwAV\")\n",
    "print(\"  - Brain correlation: GNet-based correlations\")\n",
    "print(\"  - Retrieval: Image and Brain retrieval\")\n",
    "print(\"  - Image quality: IS, FID\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== EVALUATION SETUP =====\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Initialize evaluation orchestrator\n",
    "evaluator = EvaluationOrchestrator(device=device)\n",
    "print(\"Evaluation orchestrator initialized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Evaluation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: SwAV model not implemented yet\n",
      "Warning: GNet model not loaded yet\n",
      "Evaluation orchestrator initialized!\n",
      "\n",
      "Initializing individual metrics...\n",
      "AlexNet and InceptionV3 metrics ready\n",
      "EfficientNet distance ready\n",
      "Image quality metrics (IS, FID) ready\n",
      "Low-level metrics (SSIM, PixCorr) ready\n",
      "Warning: GNet model not loaded yet\n",
      "Brain correlation metrics ready\n",
      "\n",
      "All available metrics initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "# Initialize evaluation orchestrator\n",
    "evaluator = EvaluationOrchestrator(device=device)\n",
    "print(\"Evaluation orchestrator initialized!\")\n",
    "\n",
    "# Initialize individual metrics for testing\n",
    "print(\"\\nInitializing individual metrics...\")\n",
    "\n",
    "# High-level metrics\n",
    "alexnet_metrics = AlexNetMetrics(device=device)\n",
    "inception_metrics = InceptionMetrics(device=device)\n",
    "print(\"AlexNet and InceptionV3 metrics ready\")\n",
    "\n",
    "# Distance metrics\n",
    "effnet_dist = EfficientNetDistance(device=device)\n",
    "print(\"EfficientNet distance ready\")\n",
    "\n",
    "# Image quality metrics\n",
    "is_metric = InceptionScore(device=device)\n",
    "fid_metric = FID(device=device)\n",
    "print(\"Image quality metrics (IS, FID) ready\")\n",
    "\n",
    "# Low-level metrics (if ground truth available)\n",
    "if HAS_GROUND_TRUTH:\n",
    "    ssim_metric = SSIM(device=device)\n",
    "    pixcorr_metric = PixCorr(device=device)\n",
    "    print(\"Low-level metrics (SSIM, PixCorr) ready\")\n",
    "\n",
    "# Brain correlation metrics (if fMRI data available)\n",
    "if HAS_FMRI_DATA:\n",
    "    brain_corr = BrainCorrelationMetrics(device=device)\n",
    "    print(\"Brain correlation metrics ready\")\n",
    "\n",
    "print(\"\\nAll available metrics initialized successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Evaluation\n",
    "\n",
    "**Choose your evaluation scenario:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29cba25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 50 ground truth images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading ground truth: 100%|██████████| 50/50 [00:00<00:00, 98.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth batch shape: torch.Size([50, 1, 3, 224, 224])\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting comprehensive evaluation with best reconstruction selection...\n",
      "Selecting best reconstructions using SSIM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating reconstructions: 100%|██████████| 50/50 [00:00<00:00, 429.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best reconstruction selection complete!\n",
      "Best reconstruction shape: torch.Size([50, 3, 224, 224])\n",
      "Best indices: [3 0 4 0 4 0 0 0 2 3 3 0 0 0 3 4 4 4 2 2 1 2 4 1 2 2 2 4 2 3 1 0 2 3 0 1 4\n",
      " 3 1 0 0 4 3 4 4 1 3 4 3 2]\n",
      "Score statistics:\n",
      "  Mean best score: 0.0846\n",
      "  Score range: 0.0057 to 0.3839\n",
      "\n",
      "Running evaluation on best reconstructions...\n",
      "Starting comprehensive evaluation...\n",
      "Computing low-level metrics...\n",
      "Computing high-level metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing distance metrics...\n",
      "Computing image quality metrics...\n",
      "\n",
      "============================================================\n",
      "EVALUATION RESULTS (Best Reconstructions)\n",
      "============================================================\n",
      "\n",
      "==================================================\n",
      "EVALUATION SUMMARY\n",
      "==================================================\n",
      "\n",
      "LOW LEVEL:\n",
      "------------------------------\n",
      "  SSIM: 0.0846 ± 0.0829\n",
      "  PixCorr: 0.1277 ± 0.1757\n",
      "\n",
      "HIGH LEVEL:\n",
      "------------------------------\n",
      "  AlexNet-2: 4.0000\n",
      "  AlexNet-5: 14.0000\n",
      "  CLIP: 4.0000\n",
      "  InceptionV3: 8.0000\n",
      "\n",
      "DISTANCE:\n",
      "------------------------------\n",
      "  EffNet-B: 0.8467\n",
      "  SwAV: 0.4670\n",
      "\n",
      "IMAGE QUALITY:\n",
      "------------------------------\n",
      "  IS: 8.4494\n",
      "  FID: 364.8029\n",
      "\n",
      "==================================================\n",
      "\n",
      "Best Reconstruction Analysis:\n",
      "  Images evaluated: 50\n",
      "  Reconstruction diversity: 5 different outputs selected\n",
      "  Selection distribution: [12  6 10 10 12]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Metrics\n",
    "\n",
    "**Run the evaluation based on available data:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting comprehensive evaluation with best reconstruction selection...\n",
      "Selecting best reconstructions using SSIM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating reconstructions: 100%|██████████| 50/50 [00:00<00:00, 430.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best reconstruction selection complete!\n",
      "Best reconstruction shape: torch.Size([50, 3, 224, 224])\n",
      "Best indices: [3 0 4 0 4 0 0 0 2 3 3 0 0 0 3 4 4 4 2 2 1 2 4 1 2 2 2 4 2 3 1 0 2 3 0 1 4\n",
      " 3 1 0 0 4 3 4 4 1 3 4 3 2]\n",
      "Score statistics:\n",
      "  Mean best score: 0.0846\n",
      "  Score range: 0.0057 to 0.3839\n",
      "\n",
      "Running evaluation on best reconstructions...\n",
      "Starting comprehensive evaluation...\n",
      "Computing low-level metrics...\n",
      "Computing high-level metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing distance metrics...\n",
      "Computing image quality metrics...\n",
      "\n",
      "============================================================\n",
      "EVALUATION RESULTS (Best Reconstructions)\n",
      "============================================================\n",
      "\n",
      "==================================================\n",
      "EVALUATION SUMMARY\n",
      "==================================================\n",
      "\n",
      "LOW LEVEL:\n",
      "------------------------------\n",
      "  SSIM: 0.0846 ± 0.0829\n",
      "  PixCorr: 0.1277 ± 0.1757\n",
      "\n",
      "HIGH LEVEL:\n",
      "------------------------------\n",
      "  AlexNet-2: 4.0000\n",
      "  AlexNet-5: 14.0000\n",
      "  CLIP: 4.0000\n",
      "  InceptionV3: 8.0000\n",
      "\n",
      "DISTANCE:\n",
      "------------------------------\n",
      "  EffNet-B: 0.8467\n",
      "  SwAV: 0.4542\n",
      "\n",
      "IMAGE QUALITY:\n",
      "------------------------------\n",
      "  IS: 8.4494\n",
      "  FID: 364.8029\n",
      "\n",
      "==================================================\n",
      "\n",
      "Best Reconstruction Analysis:\n",
      "  Images evaluated: 50\n",
      "  Reconstruction diversity: 5 different outputs selected\n",
      "  Selection distribution: [12  6 10 10 12]\n"
     ]
    }
   ],
   "source": [
    "# Run comprehensive evaluation\n",
    "if recon_batch is not None:\n",
    "    print(\"Starting comprehensive evaluation...\")\n",
    "    \n",
    "    # Prepare evaluation parameters\n",
    "    eval_params = {\n",
    "        'recon_batch': recon_batch,\n",
    "        'gt_batch': gt_batch if HAS_GROUND_TRUTH else None,\n",
    "        'actual_fmri': None,  # Add fMRI data if available\n",
    "        'region_masks': None,  # Add brain region masks if available\n",
    "        'real_images': gt_batch if HAS_GROUND_TRUTH else None\n",
    "    }\n",
    "    \n",
    "    # Run evaluation\n",
    "    results = evaluator.comprehensive_evaluation(**eval_params)\n",
    "    \n",
    "    # Print results\n",
    "    evaluator.print_summary(results)\n",
    "    \n",
    "else:\n",
    "    print(\"Cannot run evaluation - no reconstruction images loaded!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual Metric Testing\n",
    "\n",
    "**Test specific metrics individually:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing individual metrics...\n",
      "\n",
      "Testing AlexNet features...\n",
      "AlexNet-2 features shape: torch.Size([50, 139968])\n",
      "AlexNet-5 features shape: torch.Size([50, 43264])\n",
      "\n",
      "Testing InceptionV3 features...\n",
      "InceptionV3 features shape: torch.Size([50, 1000])\n",
      "\n",
      "Testing EfficientNet features...\n",
      "EfficientNet features shape: torch.Size([50, 1280])\n",
      "\n",
      "Computing self-similarity metrics...\n",
      "  AlexNet-2: Mean=0.3289, Std=0.0948\n",
      "  AlexNet-5: Mean=0.1593, Std=0.0870\n",
      "  InceptionV3: Mean=0.0704, Std=0.1242\n",
      "  EfficientNet: Mean=0.1738, Std=0.0994\n",
      "\n",
      "Individual metric testing completed!\n"
     ]
    }
   ],
   "source": [
    "# Test individual metrics (if reconstruction data available)\n",
    "if recon_batch is not None:\n",
    "    print(\"Testing individual metrics...\")\n",
    "    \n",
    "    # Test AlexNet features\n",
    "    print(\"\\nTesting AlexNet features...\")\n",
    "    alexnet2_feat = alexnet_metrics.extract_features(recon_batch, layer=2)\n",
    "    alexnet5_feat = alexnet_metrics.extract_features(recon_batch, layer=5)\n",
    "    print(f\"AlexNet-2 features shape: {alexnet2_feat.shape}\")\n",
    "    print(f\"AlexNet-5 features shape: {alexnet5_feat.shape}\")\n",
    "    \n",
    "    # Test InceptionV3 features\n",
    "    print(\"\\nTesting InceptionV3 features...\")\n",
    "    inception_feat = inception_metrics.extract_features(recon_batch)\n",
    "    print(f\"InceptionV3 features shape: {inception_feat.shape}\")\n",
    "    \n",
    "    # Test EfficientNet features\n",
    "    print(\"\\nTesting EfficientNet features...\")\n",
    "    effnet_feat = effnet_dist.extract_features(recon_batch)\n",
    "    print(f\"EfficientNet features shape: {effnet_feat.shape}\")\n",
    "    \n",
    "    # Compute self-similarity metrics (as proxy for quality)\n",
    "    print(\"\\nComputing self-similarity metrics...\")\n",
    "    \n",
    "    def compute_self_similarity(features, name):\n",
    "        features_norm = torch.nn.functional.normalize(features, dim=1)\n",
    "        similarities = torch.mm(features_norm, features_norm.T)\n",
    "        # Remove diagonal\n",
    "        mask = torch.eye(similarities.shape[0], dtype=bool, device=device)\n",
    "        similarities_no_diag = similarities[~mask]\n",
    "        mean_sim = similarities_no_diag.mean().item()\n",
    "        std_sim = similarities_no_diag.std().item()\n",
    "        print(f\"  {name}: Mean={mean_sim:.4f}, Std={std_sim:.4f}\")\n",
    "        return mean_sim, std_sim\n",
    "    \n",
    "    alexnet2_sim = compute_self_similarity(alexnet2_feat, \"AlexNet-2\")\n",
    "    alexnet5_sim = compute_self_similarity(alexnet5_feat, \"AlexNet-5\")\n",
    "    inception_sim = compute_self_similarity(inception_feat, \"InceptionV3\")\n",
    "    effnet_sim = compute_self_similarity(effnet_feat, \"EfficientNet\")\n",
    "    \n",
    "    print(\"\\nIndividual metric testing completed!\")\n",
    "    \n",
    "else:\n",
    "    print(\"Cannot test individual metrics - no reconstruction data available!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Summary\n",
    "\n",
    "**Current evaluation status:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVALUATION SUMMARY\n",
      "==================================================\n",
      "\n",
      "Data Status:\n",
      "  Reconstruction images: True\n",
      "  Ground truth images: True\n",
      "  fMRI data: True\n",
      "  GNet model: False\n",
      "\n",
      "Evaluation Parameters:\n",
      "  Images evaluated: 50\n",
      "  Batch size: 8\n",
      "  Device: cuda\n",
      "\n",
      "Available Metrics:\n",
      "  True Working: AlexNet-2/5, InceptionV3, EfficientNet\n",
      "  True With GT: SSIM, PixCorr, Two-way identification\n",
      "  False Need fMRI+GNet: Brain correlations\n",
      "\n",
      "Next Steps:\n",
      "  3. Add GNet model to enable brain correlation predictions\n",
      "  4. Increase NUM_IMAGES_TO_EVALUATE for more comprehensive evaluation\n"
     ]
    }
   ],
   "source": [
    "# Create results summary\n",
    "print(\"EVALUATION SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"\\nData Status:\")\n",
    "print(f\"  Reconstruction images: {'True' if recon_batch is not None else 'False'}\")\n",
    "print(f\"  Ground truth images: {'True' if HAS_GROUND_TRUTH and gt_batch is not None else 'False'}\")\n",
    "print(f\"  fMRI data: {'True' if HAS_FMRI_DATA else 'False'}\")\n",
    "print(f\"  GNet model: {'True' if HAS_GNET_MODEL else 'False'}\")\n",
    "\n",
    "print(f\"\\nEvaluation Parameters:\")\n",
    "print(f\"  Images evaluated: {NUM_IMAGES_TO_EVALUATE}\")\n",
    "print(f\"  Batch size: {BATCH_SIZE}\")\n",
    "print(f\"  Device: {device}\")\n",
    "\n",
    "print(f\"\\nAvailable Metrics:\")\n",
    "print(f\"  True Working: AlexNet-2/5, InceptionV3, EfficientNet\")\n",
    "if HAS_GROUND_TRUTH:\n",
    "    print(f\"  True With GT: SSIM, PixCorr, Two-way identification\")\n",
    "else:\n",
    "    print(f\"  False Need GT: SSIM, PixCorr, Two-way identification\")\n",
    "    \n",
    "if HAS_FMRI_DATA and HAS_GNET_MODEL:\n",
    "    print(f\"  True With fMRI: Brain correlations\")\n",
    "else:\n",
    "    print(f\"  False Need fMRI+GNet: Brain correlations\")\n",
    "\n",
    "print(f\"\\nNext Steps:\")\n",
    "if not HAS_GROUND_TRUTH:\n",
    "    print(f\"  1. Add ground truth images to enable SSIM, PixCorr, two-way identification\")\n",
    "if not HAS_FMRI_DATA:\n",
    "    print(f\"  2. Add fMRI data to enable brain correlation metrics\")\n",
    "if not HAS_GNET_MODEL:\n",
    "    print(f\"  3. Add GNet model to enable brain correlation predictions\")\n",
    "print(f\"  4. Increase NUM_IMAGES_TO_EVALUATE for more comprehensive evaluation\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Checklist\n",
    "\n",
    "### True **COMPLETED**\n",
    "- **AlexNet-2**: ✓ Working (feature similarity)\n",
    "- **AlexNet-5**: ✓ Working (feature similarity) \n",
    "- **InceptionV3**: ✓ Working (feature similarity)\n",
    "- **EfficientNet-B1**: ✓ Working (distance metrics)\n",
    "\n",
    "### False **STILL NEEDED**\n",
    "\n",
    "#### **Low-Level Metrics**\n",
    "- [ ] **SSIM**: Need ground truth images\n",
    "- [ ] **PixCorr**: Need ground truth images\n",
    "\n",
    "#### **High-Level Metrics** \n",
    "- [ ] **CLIP**: Need ground truth images for two-way identification\n",
    "- [ ] **Two-way identification**: Need ground truth images\n",
    "\n",
    "#### **Distance Metrics**\n",
    "- [ ] **SwAV**: Need SwAV model implementation\n",
    "\n",
    "#### **Brain Correlation Scores**\n",
    "- [ ] **GNet model**: Need to load GNet model\n",
    "- [ ] **V1-V4 correlations**: Need fMRI data + GNet\n",
    "- [ ] **Higher Visual cortex correlation**\n",
    "- [ ] **Whole Visual Cortex correlation**\n",
    "\n",
    "#### **Retrieval Metrics**\n",
    "- [ ] **Image Retrieval**: Need 300 candidate images\n",
    "- [ ] **Brain Retrieval**: Need 300 candidate fMRI scans\n",
    "\n",
    "#### **Image Quality Metrics**\n",
    "- [ ] **IS (Inception Score)**: Need implementation\n",
    "- [ ] **FID (Fréchet Inception Distance)**: Need implementation\n",
    "\n",
    "### **Key Missing Components:**\n",
    "1. **Ground truth images** (for SSIM, PixCorr, two-way identification)\n",
    "2. **GNet model** (for brain correlations)\n",
    "3. **Actual fMRI data** (for brain correlations)\n",
    "4. **CLIP model** (for CLIP metrics)\n",
    "5. **SwAV model** (for SwAV distance)\n",
    "6. **Retrieval datasets** (300 images + 300 fMRI scans)\n",
    "\n",
    "**Current Status**: ~20% of metrics working. Main blockers: missing ground truth images, GNet model, and fMRI data.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
