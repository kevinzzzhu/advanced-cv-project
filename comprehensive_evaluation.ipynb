{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Comprehensive fMRI Reconstruction Evaluation\n",
        "\n",
        "This notebook provides a systematic evaluation framework for fMRI-to-image reconstruction methods using multiple quality metrics.\n",
        "\n",
        "## Overview\n",
        "\n",
        "The evaluation system supports:\n",
        "- Low-level metrics: SSIM, Pixel Correlation\n",
        "- High-level metrics: AlexNet, CLIP, InceptionV3\n",
        "- Distance metrics: EfficientNet, SwAV\n",
        "- Image quality: Inception Score, FID\n",
        "- Brain correlation: GNet-based correlations\n",
        "- Retrieval metrics: Image and Brain retrieval\n",
        "\n",
        "## Configuration\n",
        "\n",
        "Modify the parameters below to customize your evaluation setup.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration and Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Base output directory: /home/kevin/Documents/ACV/Project/advanced-cv-project/outputs_all/subj01\n",
            "Ground truth directory: /home/kevin/Documents/ACV/Project/advanced-cv-project/outputs_all/subj01/ground_truth\n",
            "fMRI data directory: /home/kevin/Documents/ACV/Project/advanced-cv-project/MindEyeV2\n",
            "Images to evaluate: 50\n",
            "Batch size: 8\n",
            "Device: cuda\n",
            "Has ground truth: True\n",
            "Has fMRI data: True\n",
            "Has GNet model: False\n",
            "Results will be saved to: /home/kevin/Documents/ACV/Project/advanced-cv-project/evaluation_results.json\n"
          ]
        }
      ],
      "source": [
        "# ===== EVALUATION CONFIGURATION =====\n",
        "import os\n",
        "import json\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "\n",
        "# Paths\n",
        "PROJECT_ROOT = '/home/kevin/Documents/ACV/Project/advanced-cv-project'\n",
        "BASE_OUTPUT_DIR = f'{PROJECT_ROOT}/outputs_all/subj01'\n",
        "GT_DIR = f'{PROJECT_ROOT}/outputs_all/subj01/ground_truth'\n",
        "FMRI_DIR = f'{PROJECT_ROOT}/MindEyeV2'\n",
        "\n",
        "# Evaluation parameters\n",
        "NUM_IMAGES_TO_EVALUATE = 50\n",
        "BATCH_SIZE = 8\n",
        "DEVICE = 'cuda'\n",
        "\n",
        "# Data availability flags\n",
        "HAS_GROUND_TRUTH = True\n",
        "HAS_FMRI_DATA = True\n",
        "HAS_GNET_MODEL = False\n",
        "\n",
        "# Results storage\n",
        "RESULTS_FILE = f'{PROJECT_ROOT}/evaluation_results.json'\n",
        "\n",
        "print(f\"Base output directory: {BASE_OUTPUT_DIR}\")\n",
        "print(f\"Ground truth directory: {GT_DIR}\")\n",
        "print(f\"fMRI data directory: {FMRI_DIR}\")\n",
        "print(f\"Images to evaluate: {NUM_IMAGES_TO_EVALUATE}\")\n",
        "print(f\"Batch size: {BATCH_SIZE}\")\n",
        "print(f\"Device: {DEVICE}\")\n",
        "print(f\"Has ground truth: {HAS_GROUND_TRUTH}\")\n",
        "print(f\"Has fMRI data: {HAS_FMRI_DATA}\")\n",
        "print(f\"Has GNet model: {HAS_GNET_MODEL}\")\n",
        "print(f\"Results will be saved to: {RESULTS_FILE}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experimental Directory Discovery\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scanning method directory: brain_scheduling\n",
            "  Scanning guidance scale: 100000\n",
            "    Scanning guidance strength: 0.4\n",
            "      Found experiment: /home/kevin/Documents/ACV/Project/advanced-cv-project/outputs_all/subj01/brain_scheduling/100000/0.4/20251027_192430\n",
            "    Scanning guidance strength: 0.2\n",
            "      Found experiment: /home/kevin/Documents/ACV/Project/advanced-cv-project/outputs_all/subj01/brain_scheduling/100000/0.2/20251026_215211\n",
            "    Scanning guidance strength: 0.1\n",
            "      Found experiment: /home/kevin/Documents/ACV/Project/advanced-cv-project/outputs_all/subj01/brain_scheduling/100000/0.1/20251027_200225\n",
            "  Scanning guidance scale: 30000\n",
            "    Scanning guidance strength: 0.4\n",
            "      Found experiment: /home/kevin/Documents/ACV/Project/advanced-cv-project/outputs_all/subj01/brain_scheduling/30000/0.4/20251027_181755\n",
            "    Scanning guidance strength: 0.2\n",
            "      Found experiment: /home/kevin/Documents/ACV/Project/advanced-cv-project/outputs_all/subj01/brain_scheduling/30000/0.2/20251026_212457\n",
            "    Scanning guidance strength: 0.1\n",
            "      Found experiment: /home/kevin/Documents/ACV/Project/advanced-cv-project/outputs_all/subj01/brain_scheduling/30000/0.1/20251027_185522\n",
            "  Scanning guidance scale: 300000\n",
            "    Scanning guidance strength: 0.4\n",
            "      Found experiment: /home/kevin/Documents/ACV/Project/advanced-cv-project/outputs_all/subj01/brain_scheduling/300000/0.4/20251027_171904\n",
            "    Scanning guidance strength: 0.2\n",
            "      Found experiment: /home/kevin/Documents/ACV/Project/advanced-cv-project/outputs_all/subj01/brain_scheduling/300000/0.2/20251026_205738\n",
            "    Scanning guidance strength: 0.1\n",
            "      Found experiment: /home/kevin/Documents/ACV/Project/advanced-cv-project/outputs_all/subj01/brain_scheduling/300000/0.1/20251027_175307\n",
            "Scanning method directory: cp_4096_v1_with_z\n",
            "  Scanning guidance scale: 8000\n",
            "    Scanning guidance strength: 0.2\n",
            "      Found experiment: /home/kevin/Documents/ACV/Project/advanced-cv-project/outputs_all/subj01/cp_4096_v1_with_z/8000/0.2/20251026_162044\n",
            "  Scanning guidance scale: 3000\n",
            "    Scanning guidance strength: 0.4\n",
            "      Found experiment: /home/kevin/Documents/ACV/Project/advanced-cv-project/outputs_all/subj01/cp_4096_v1_with_z/3000/0.4/20251026_085458\n",
            "    Scanning guidance strength: 0.2\n",
            "      Found experiment: /home/kevin/Documents/ACV/Project/advanced-cv-project/outputs_all/subj01/cp_4096_v1_with_z/3000/0.2/20251026_080314\n",
            "    Scanning guidance strength: 0.1\n",
            "      Found experiment: /home/kevin/Documents/ACV/Project/advanced-cv-project/outputs_all/subj01/cp_4096_v1_with_z/3000/0.1/20251026_083046\n",
            "  Scanning guidance scale: 100000\n",
            "    Scanning guidance strength: 0.2\n",
            "      Found experiment: /home/kevin/Documents/ACV/Project/advanced-cv-project/outputs_all/subj01/cp_4096_v1_with_z/100000/0.2/20251026_152601\n",
            "  Scanning guidance scale: 3000000\n",
            "    Scanning guidance strength: 0.4\n",
            "      Found experiment: /home/kevin/Documents/ACV/Project/advanced-cv-project/outputs_all/subj01/cp_4096_v1_with_z/3000000/0.4/20251026_043948\n",
            "    Scanning guidance strength: 0.2\n",
            "      Found experiment: /home/kevin/Documents/ACV/Project/advanced-cv-project/outputs_all/subj01/cp_4096_v1_with_z/3000000/0.2/20251026_034747\n",
            "    Scanning guidance strength: 0.1\n",
            "      Found experiment: /home/kevin/Documents/ACV/Project/advanced-cv-project/outputs_all/subj01/cp_4096_v1_with_z/3000000/0.1/20251026_041544\n",
            "  Scanning guidance scale: 200000\n",
            "    Scanning guidance strength: 0.2\n",
            "      Found experiment: /home/kevin/Documents/ACV/Project/advanced-cv-project/outputs_all/subj01/cp_4096_v1_with_z/200000/0.2/20251026_155320\n",
            "  Scanning guidance scale: 30000\n",
            "    Scanning guidance strength: 0.4\n",
            "      Found experiment: /home/kevin/Documents/ACV/Project/advanced-cv-project/outputs_all/subj01/cp_4096_v1_with_z/30000/0.4/20251026_072950\n",
            "    Scanning guidance strength: 0.2\n",
            "      Found experiment: /home/kevin/Documents/ACV/Project/advanced-cv-project/outputs_all/subj01/cp_4096_v1_with_z/30000/0.2/20251026_063805\n",
            "    Scanning guidance strength: 0.1\n",
            "      Found experiment: /home/kevin/Documents/ACV/Project/advanced-cv-project/outputs_all/subj01/cp_4096_v1_with_z/30000/0.1/20251026_070537\n",
            "  Scanning guidance scale: 300000\n",
            "    Scanning guidance strength: 0.4\n",
            "      Found experiment: /home/kevin/Documents/ACV/Project/advanced-cv-project/outputs_all/subj01/cp_4096_v1_with_z/300000/0.4/20251026_060443\n",
            "    Scanning guidance strength: 0.2\n",
            "      Found experiment: /home/kevin/Documents/ACV/Project/advanced-cv-project/outputs_all/subj01/cp_4096_v1_with_z/300000/0.2/20251026_051305\n",
            "    Scanning guidance strength: 0.1\n",
            "      Found experiment: /home/kevin/Documents/ACV/Project/advanced-cv-project/outputs_all/subj01/cp_4096_v1_with_z/300000/0.1/20251026_054035\n",
            "Scanning method directory: cp_4096_v1_no_z\n",
            "  Scanning guidance scale: 100000\n",
            "    Scanning guidance strength: 0.4\n",
            "      Found experiment: /home/kevin/Documents/ACV/Project/advanced-cv-project/outputs_all/subj01/cp_4096_v1_no_z/100000/0.4/20251027_095725\n",
            "    Scanning guidance strength: 0.2\n",
            "      Found experiment: /home/kevin/Documents/ACV/Project/advanced-cv-project/outputs_all/subj01/cp_4096_v1_no_z/100000/0.2/20251027_090137\n",
            "    Scanning guidance strength: 0.1\n",
            "      Found experiment: /home/kevin/Documents/ACV/Project/advanced-cv-project/outputs_all/subj01/cp_4096_v1_no_z/100000/0.1/20251027_093119\n",
            "  Scanning guidance scale: 30000\n",
            "    Scanning guidance strength: 0.4\n",
            "      Found experiment: /home/kevin/Documents/ACV/Project/advanced-cv-project/outputs_all/subj01/cp_4096_v1_no_z/30000/0.4/20251027_082536\n",
            "    Scanning guidance strength: 0.2\n",
            "      Found experiment: /home/kevin/Documents/ACV/Project/advanced-cv-project/outputs_all/subj01/cp_4096_v1_no_z/30000/0.2/20251027_073001\n",
            "    Scanning guidance strength: 0.1\n",
            "      Found experiment: /home/kevin/Documents/ACV/Project/advanced-cv-project/outputs_all/subj01/cp_4096_v1_no_z/30000/0.1/20251027_075937\n",
            "  Scanning guidance scale: 300000\n",
            "    Scanning guidance strength: 0.4\n",
            "      Found experiment: /home/kevin/Documents/ACV/Project/advanced-cv-project/outputs_all/subj01/cp_4096_v1_no_z/300000/0.4/20251027_065405\n",
            "    Scanning guidance strength: 0.2\n",
            "      Found experiment: /home/kevin/Documents/ACV/Project/advanced-cv-project/outputs_all/subj01/cp_4096_v1_no_z/300000/0.2/20251027_055838\n",
            "    Scanning guidance strength: 2.0\n",
            "      Found experiment: /home/kevin/Documents/ACV/Project/advanced-cv-project/outputs_all/subj01/cp_4096_v1_no_z/300000/2.0/20251026_143307\n",
            "    Scanning guidance strength: 0.1\n",
            "      Found experiment: /home/kevin/Documents/ACV/Project/advanced-cv-project/outputs_all/subj01/cp_4096_v1_no_z/300000/0.1/20251027_062810\n",
            "\n",
            "Found 34 experimental directories:\n",
            "  1. /home/kevin/Documents/ACV/Project/advanced-cv-project/outputs_all/subj01/brain_scheduling/100000/0.4/20251027_192430\n",
            "  2. /home/kevin/Documents/ACV/Project/advanced-cv-project/outputs_all/subj01/brain_scheduling/100000/0.2/20251026_215211\n",
            "  3. /home/kevin/Documents/ACV/Project/advanced-cv-project/outputs_all/subj01/brain_scheduling/100000/0.1/20251027_200225\n",
            "  4. /home/kevin/Documents/ACV/Project/advanced-cv-project/outputs_all/subj01/brain_scheduling/30000/0.4/20251027_181755\n",
            "  5. /home/kevin/Documents/ACV/Project/advanced-cv-project/outputs_all/subj01/brain_scheduling/30000/0.2/20251026_212457\n",
            "  6. /home/kevin/Documents/ACV/Project/advanced-cv-project/outputs_all/subj01/brain_scheduling/30000/0.1/20251027_185522\n",
            "  7. /home/kevin/Documents/ACV/Project/advanced-cv-project/outputs_all/subj01/brain_scheduling/300000/0.4/20251027_171904\n",
            "  8. /home/kevin/Documents/ACV/Project/advanced-cv-project/outputs_all/subj01/brain_scheduling/300000/0.2/20251026_205738\n",
            "  9. /home/kevin/Documents/ACV/Project/advanced-cv-project/outputs_all/subj01/brain_scheduling/300000/0.1/20251027_175307\n",
            "  10. /home/kevin/Documents/ACV/Project/advanced-cv-project/outputs_all/subj01/cp_4096_v1_with_z/8000/0.2/20251026_162044\n",
            "  11. /home/kevin/Documents/ACV/Project/advanced-cv-project/outputs_all/subj01/cp_4096_v1_with_z/3000/0.4/20251026_085458\n",
            "  12. /home/kevin/Documents/ACV/Project/advanced-cv-project/outputs_all/subj01/cp_4096_v1_with_z/3000/0.2/20251026_080314\n",
            "  13. /home/kevin/Documents/ACV/Project/advanced-cv-project/outputs_all/subj01/cp_4096_v1_with_z/3000/0.1/20251026_083046\n",
            "  14. /home/kevin/Documents/ACV/Project/advanced-cv-project/outputs_all/subj01/cp_4096_v1_with_z/100000/0.2/20251026_152601\n",
            "  15. /home/kevin/Documents/ACV/Project/advanced-cv-project/outputs_all/subj01/cp_4096_v1_with_z/3000000/0.4/20251026_043948\n",
            "  16. /home/kevin/Documents/ACV/Project/advanced-cv-project/outputs_all/subj01/cp_4096_v1_with_z/3000000/0.2/20251026_034747\n",
            "  17. /home/kevin/Documents/ACV/Project/advanced-cv-project/outputs_all/subj01/cp_4096_v1_with_z/3000000/0.1/20251026_041544\n",
            "  18. /home/kevin/Documents/ACV/Project/advanced-cv-project/outputs_all/subj01/cp_4096_v1_with_z/200000/0.2/20251026_155320\n",
            "  19. /home/kevin/Documents/ACV/Project/advanced-cv-project/outputs_all/subj01/cp_4096_v1_with_z/30000/0.4/20251026_072950\n",
            "  20. /home/kevin/Documents/ACV/Project/advanced-cv-project/outputs_all/subj01/cp_4096_v1_with_z/30000/0.2/20251026_063805\n",
            "  21. /home/kevin/Documents/ACV/Project/advanced-cv-project/outputs_all/subj01/cp_4096_v1_with_z/30000/0.1/20251026_070537\n",
            "  22. /home/kevin/Documents/ACV/Project/advanced-cv-project/outputs_all/subj01/cp_4096_v1_with_z/300000/0.4/20251026_060443\n",
            "  23. /home/kevin/Documents/ACV/Project/advanced-cv-project/outputs_all/subj01/cp_4096_v1_with_z/300000/0.2/20251026_051305\n",
            "  24. /home/kevin/Documents/ACV/Project/advanced-cv-project/outputs_all/subj01/cp_4096_v1_with_z/300000/0.1/20251026_054035\n",
            "  25. /home/kevin/Documents/ACV/Project/advanced-cv-project/outputs_all/subj01/cp_4096_v1_no_z/100000/0.4/20251027_095725\n",
            "  26. /home/kevin/Documents/ACV/Project/advanced-cv-project/outputs_all/subj01/cp_4096_v1_no_z/100000/0.2/20251027_090137\n",
            "  27. /home/kevin/Documents/ACV/Project/advanced-cv-project/outputs_all/subj01/cp_4096_v1_no_z/100000/0.1/20251027_093119\n",
            "  28. /home/kevin/Documents/ACV/Project/advanced-cv-project/outputs_all/subj01/cp_4096_v1_no_z/30000/0.4/20251027_082536\n",
            "  29. /home/kevin/Documents/ACV/Project/advanced-cv-project/outputs_all/subj01/cp_4096_v1_no_z/30000/0.2/20251027_073001\n",
            "  30. /home/kevin/Documents/ACV/Project/advanced-cv-project/outputs_all/subj01/cp_4096_v1_no_z/30000/0.1/20251027_075937\n",
            "  31. /home/kevin/Documents/ACV/Project/advanced-cv-project/outputs_all/subj01/cp_4096_v1_no_z/300000/0.4/20251027_065405\n",
            "  32. /home/kevin/Documents/ACV/Project/advanced-cv-project/outputs_all/subj01/cp_4096_v1_no_z/300000/0.2/20251027_055838\n",
            "  33. /home/kevin/Documents/ACV/Project/advanced-cv-project/outputs_all/subj01/cp_4096_v1_no_z/300000/2.0/20251026_143307\n",
            "  34. /home/kevin/Documents/ACV/Project/advanced-cv-project/outputs_all/subj01/cp_4096_v1_no_z/300000/0.1/20251027_062810\n",
            "\n",
            "Loaded existing results with 28 experiments\n"
          ]
        }
      ],
      "source": [
        "# ===== FIND EXPERIMENTAL DIRECTORIES =====\n",
        "def find_experimental_dirs(base_dir):\n",
        "    \"\"\"\n",
        "    Find all experimental directories with timestamp subdirectories\n",
        "    \"\"\"\n",
        "    experimental_dirs = []\n",
        "    base_path = Path(base_dir)\n",
        "    \n",
        "    if not base_path.exists():\n",
        "        print(f\"Base directory not found: {base_dir}\")\n",
        "        return experimental_dirs\n",
        "    \n",
        "    # Look for nested timestamp directories in the structure:\n",
        "    # cp_4096_v1_with_z/{guidance_scale}/{guidance_strength}/{timestamp}\n",
        "    # cp_4096_v1_no_z/{guidance_scale}/{guidance_strength}/{timestamp}\n",
        "    # brain_scheduling/{guidance_scale}/{guidance_strength}/{timestamp}\n",
        "    \n",
        "    for method_dir in base_path.iterdir():\n",
        "        if method_dir.is_dir() and (method_dir.name.startswith('cp_4096_v1') or method_dir.name == 'brain_scheduling'):\n",
        "            print(f\"Scanning method directory: {method_dir.name}\")\n",
        "            \n",
        "            for guidance_scale_dir in method_dir.iterdir():\n",
        "                if guidance_scale_dir.is_dir() and guidance_scale_dir.name.isdigit():\n",
        "                    print(f\"  Scanning guidance scale: {guidance_scale_dir.name}\")\n",
        "                    \n",
        "                    for guidance_strength_dir in guidance_scale_dir.iterdir():\n",
        "                        if guidance_strength_dir.is_dir():\n",
        "                            print(f\"    Scanning guidance strength: {guidance_strength_dir.name}\")\n",
        "                            \n",
        "                            for timestamp_dir in guidance_strength_dir.iterdir():\n",
        "                                if timestamp_dir.is_dir() and len(timestamp_dir.name) == 15 and timestamp_dir.name[8] == '_':\n",
        "                                    experimental_dirs.append(timestamp_dir)\n",
        "                                    print(f\"      Found experiment: {timestamp_dir}\")\n",
        "    \n",
        "    return experimental_dirs\n",
        "\n",
        "# Find all experimental directories\n",
        "experimental_dirs = find_experimental_dirs(BASE_OUTPUT_DIR)\n",
        "print(f\"\\nFound {len(experimental_dirs)} experimental directories:\")\n",
        "for i, exp_dir in enumerate(experimental_dirs):\n",
        "    print(f\"  {i+1}. {exp_dir}\")\n",
        "\n",
        "# Load existing results with error handling\n",
        "def load_existing_results_safe(filename):\n",
        "    \"\"\"Load existing results with proper error handling\"\"\"\n",
        "    if not os.path.exists(filename):\n",
        "        print(f\"\\nNo existing results file found, starting fresh\")\n",
        "        return {}\n",
        "    \n",
        "    try:\n",
        "        with open(filename, 'r') as f:\n",
        "            results = json.load(f)\n",
        "        print(f\"\\nLoaded existing results with {len(results)} experiments\")\n",
        "        return results\n",
        "    except (json.JSONDecodeError, ValueError) as e:\n",
        "        print(f\"\\nError loading existing results file: {e}\")\n",
        "        print(f\"File may be corrupted. Starting fresh...\")\n",
        "        # Optionally backup the corrupted file\n",
        "        backup_file = filename + \".corrupted\"\n",
        "        try:\n",
        "            import shutil\n",
        "            shutil.move(filename, backup_file)\n",
        "            print(f\"Corrupted file backed up to: {backup_file}\")\n",
        "        except Exception as backup_error:\n",
        "            print(f\"Could not backup corrupted file: {backup_error}\")\n",
        "        return {}\n",
        "    except Exception as e:\n",
        "        print(f\"\\nUnexpected error loading results: {e}\")\n",
        "        return {}\n",
        "\n",
        "# Load existing results with error handling\n",
        "all_results = load_existing_results_safe(RESULTS_FILE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "GPU: NVIDIA GeForce RTX 5070 Ti\n",
            "Memory: 16.60 GB\n"
          ]
        }
      ],
      "source": [
        "# ===== IMPORT LIBRARIES =====\n",
        "import os \n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Add project to path\n",
        "import sys\n",
        "sys.path.insert(0, PROJECT_ROOT)\n",
        "\n",
        "# Check GPU availability\n",
        "device = torch.device(DEVICE if torch.cuda.is_available() and DEVICE == 'cuda' else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initialize Evaluation Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in /home/kevin/.cache/torch/hub/facebookresearch_swav_main\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SwAV model loaded successfully\n",
            "Warning: GNet model not loaded yet\n",
            "Evaluation orchestrator initialized!\n",
            "\n",
            "Initializing individual metrics...\n",
            "AlexNet and InceptionV3 metrics ready\n",
            "EfficientNet distance ready\n",
            "Image quality metrics (IS, FID) ready\n",
            "Low-level metrics (SSIM, PixCorr) ready\n",
            "Warning: GNet model not loaded yet\n",
            "Brain correlation metrics ready\n",
            "\n",
            "All available metrics initialized successfully!\n"
          ]
        }
      ],
      "source": [
        "# ===== INITIALIZE EVALUATION METRICS =====\n",
        "from evaluation.orchestrator import EvaluationOrchestrator\n",
        "from evaluation.low_level import SSIM, PixCorr\n",
        "from evaluation.high_level import AlexNetMetrics, CLIPMetrics, InceptionMetrics\n",
        "from evaluation.distance import EfficientNetDistance, SwAVDistance\n",
        "from evaluation.brain_correlation import BrainCorrelationMetrics\n",
        "from evaluation.retrieval import ImageRetrieval, BrainRetrieval\n",
        "from evaluation.image_quality import InceptionScore, FID\n",
        "\n",
        "# Initialize evaluation orchestrator\n",
        "evaluator = EvaluationOrchestrator(device=device)\n",
        "print(\"Evaluation orchestrator initialized!\")\n",
        "\n",
        "# Initialize individual metrics for testing\n",
        "print(\"\\nInitializing individual metrics...\")\n",
        "\n",
        "# High-level metrics\n",
        "alexnet_metrics = AlexNetMetrics(device=device)\n",
        "inception_metrics = InceptionMetrics(device=device)\n",
        "print(\"AlexNet and InceptionV3 metrics ready\")\n",
        "\n",
        "# Distance metrics\n",
        "effnet_dist = EfficientNetDistance(device=device)\n",
        "print(\"EfficientNet distance ready\")\n",
        "\n",
        "# Image quality metrics\n",
        "is_metric = InceptionScore(device=device)\n",
        "fid_metric = FID(device=device)\n",
        "print(\"Image quality metrics (IS, FID) ready\")\n",
        "\n",
        "# Low-level metrics (if ground truth available)\n",
        "if HAS_GROUND_TRUTH:\n",
        "    ssim_metric = SSIM(device=device)\n",
        "    pixcorr_metric = PixCorr(device=device)\n",
        "    print(\"Low-level metrics (SSIM, PixCorr) ready\")\n",
        "\n",
        "# Brain correlation metrics (if fMRI data available)\n",
        "if HAS_FMRI_DATA:\n",
        "    brain_corr = BrainCorrelationMetrics(device=device)\n",
        "    print(\"Brain correlation metrics ready\")\n",
        "\n",
        "print(\"\\nAll available metrics initialized successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Ground Truth Image Loading\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_ground_truth_images_corrected():\n",
        "    \"\"\"Load and preprocess ground truth images exactly like original test_orchestrator.py\"\"\"\n",
        "    if not HAS_GROUND_TRUTH:\n",
        "        print(\"Ground truth not available, skipping...\")\n",
        "        return None\n",
        "    \n",
        "    # Load and preprocess ground truth images (exactly like original)\n",
        "    from torchvision import transforms\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "    \n",
        "    # Load 50 ground truth images (like original) - in numerical order 0-49\n",
        "    gt_tensors = []\n",
        "    for i in tqdm(range(50), desc=\"Loading ground truth\"):\n",
        "        gt_path = os.path.join(GT_DIR, f\"{i:05d}.png\")\n",
        "        gt_img = Image.open(gt_path)\n",
        "        gt_tensor = transform(gt_img)\n",
        "        gt_tensors.append(gt_tensor)\n",
        "    \n",
        "    gt_batch = torch.stack(gt_tensors, dim=0).to(device)\n",
        "    print(f\"GT batch shape: {gt_batch.shape}\")\n",
        "    return gt_batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Image Loading Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_reconstruction_images(exp_dir, max_images=None):\n",
        "    \"\"\"Load reconstruction images exactly like original test_orchestrator.py\"\"\"\n",
        "    if max_images is None:\n",
        "        max_images = 50  # Load 50 concatenated images (each contains 5 reconstructions)\n",
        "    \n",
        "    # Load and preprocess images (exactly like original)\n",
        "    from torchvision import transforms\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "    \n",
        "    recon_tensors = []\n",
        "    \n",
        "    # Load reconstruction images (exactly like original)\n",
        "    for i in range(max_images):  # Load 50 concatenated images\n",
        "        recon_path = os.path.join(exp_dir, f\"{i:05d}.png\")\n",
        "        recon_img = Image.open(recon_path)\n",
        "        \n",
        "        if recon_img.size == (2560, 512):  # Concatenated\n",
        "            # Split into 5 individual reconstructions\n",
        "            for j in range(5):\n",
        "                left = j * 512\n",
        "                right = (j + 1) * 512\n",
        "                individual_img = recon_img.crop((left, 0, right, 512))\n",
        "                individual_img = individual_img.resize((224, 224), Image.Resampling.LANCZOS)\n",
        "                tensor = transform(individual_img)\n",
        "                recon_tensors.append(tensor)\n",
        "    \n",
        "    recon_batch = torch.stack(recon_tensors, dim=0).to(device)\n",
        "    print(f\"Recon batch shape: {recon_batch.shape}\")\n",
        "    return recon_batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Single Experiment Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ===== SINGLE EXPERIMENT EVALUATION =====\n",
        "def evaluate_single_experiment(exp_dir, exp_name):\n",
        "    \"\"\"Evaluate a single experimental directory with 5 reconstructions per ground truth\"\"\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"EVALUATING: {exp_name}\")\n",
        "    print(f\"Directory: {exp_dir}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    # Load ground truth images first\n",
        "    gt_batch = load_ground_truth_images_corrected()\n",
        "    if gt_batch is None:\n",
        "        print(\"No ground truth available, skipping evaluation\")\n",
        "        return None\n",
        "    \n",
        "    # Load reconstruction images\n",
        "    recon_batch = load_reconstruction_images(exp_dir)\n",
        "    if recon_batch is None:\n",
        "        return None\n",
        "    \n",
        "    # Run evaluation\n",
        "    try:\n",
        "        print(\"Running comprehensive evaluation...\")\n",
        "        \n",
        "        # Handle 5 reconstructions per ground truth image\n",
        "        if recon_batch.shape[0] == 250 and gt_batch is not None and gt_batch.shape[0] == 50:\n",
        "            # We have 250 reconstructions and 50 ground truth images\n",
        "            # This means 5 reconstructions per ground truth image\n",
        "            print(\"Detected 5 reconstructions per ground truth image\")\n",
        "            \n",
        "            # Group reconstructions by ground truth image\n",
        "            num_gt_images = gt_batch.shape[0]\n",
        "            reconstructions_per_gt = recon_batch.shape[0] // num_gt_images\n",
        "            \n",
        "            print(f\"Grouping {reconstructions_per_gt} reconstructions per ground truth image\")\n",
        "            \n",
        "            # Evaluate each group and select the best\n",
        "            best_reconstructions = []\n",
        "            best_scores = []\n",
        "            \n",
        "            for gt_idx in range(num_gt_images):\n",
        "                gt_image = gt_batch[gt_idx:gt_idx+1]  # Shape: [1, 3, 224, 224]\n",
        "                \n",
        "                # Get the 5 reconstructions for this ground truth image\n",
        "                start_idx = gt_idx * reconstructions_per_gt\n",
        "                end_idx = start_idx + reconstructions_per_gt\n",
        "                group_reconstructions = recon_batch[start_idx:end_idx]  # Shape: [5, 3, 224, 224]\n",
        "                \n",
        "                # Evaluate each reconstruction in this group\n",
        "                group_scores = []\n",
        "                for recon_idx in range(reconstructions_per_gt):\n",
        "                    recon_image = group_reconstructions[recon_idx:recon_idx+1]  # Shape: [1, 3, 224, 224]\n",
        "                    \n",
        "                    # Compute SSIM for this reconstruction\n",
        "                    ssim_val = evaluator.ssim.compute(recon_image, gt_image)\n",
        "                    group_scores.append(ssim_val)\n",
        "                \n",
        "                # Find the best reconstruction for this ground truth image\n",
        "                best_idx = np.argmax(group_scores)\n",
        "                best_recon = group_reconstructions[best_idx:best_idx+1]\n",
        "                best_score = group_scores[best_idx]\n",
        "                \n",
        "                best_reconstructions.append(best_recon)\n",
        "                best_scores.append(best_score)\n",
        "                \n",
        "                print(f\"  GT {gt_idx}: Best SSIM = {best_score:.4f} (reconstruction {best_idx})\")\n",
        "            \n",
        "            # Stack the best reconstructions\n",
        "            best_recon_batch = torch.cat(best_reconstructions, dim=0)\n",
        "            print(f\"Selected best reconstructions: {best_recon_batch.shape}\")\n",
        "            \n",
        "            # Now evaluate the best reconstructions\n",
        "            eval_params = {\n",
        "                'recon_batch': best_recon_batch,\n",
        "                'gt_batch': gt_batch,\n",
        "                'actual_fmri': None,  # Add if available\n",
        "                'region_masks': None,  # Add if available\n",
        "                'real_images': None   # Add if available\n",
        "            }\n",
        "            \n",
        "            results = evaluator.comprehensive_evaluation(**eval_params)\n",
        "        \n",
        "        else:\n",
        "            # Handle other cases (single reconstructions, etc.)\n",
        "            print(f\"Reconstruction batch shape: {recon_batch.shape}\")\n",
        "            if gt_batch is not None:\n",
        "                print(f\"Ground truth batch shape: {gt_batch.shape}\")\n",
        "            \n",
        "            eval_params = {\n",
        "                'recon_batch': recon_batch,\n",
        "                'gt_batch': gt_batch,\n",
        "                'actual_fmri': None,\n",
        "                'region_masks': None,\n",
        "                'real_images': None\n",
        "            }\n",
        "            \n",
        "            results = evaluator.comprehensive_evaluation(**eval_params)\n",
        "        \n",
        "        # Extract experiment metadata from path\n",
        "        path_parts = exp_dir.parts\n",
        "        method_name = path_parts[-4]  # cp_4096_v1_with_z, cp_4096_v1_no_z, or brain_scheduling\n",
        "        guidance_scale = path_parts[-3]  # 3000, 30000, etc.\n",
        "        guidance_strength = path_parts[-2]  # 0.1, 0.2, 0.4\n",
        "        timestamp = path_parts[-1]  # 20251026_143307\n",
        "        \n",
        "        # Add metadata\n",
        "        results['experiment_name'] = f\"{method_name}_scale{guidance_scale}_str{guidance_strength}_{timestamp}\"\n",
        "        results['experiment_dir'] = str(exp_dir)\n",
        "        results['method_name'] = method_name\n",
        "        results['guidance_scale'] = guidance_scale\n",
        "        results['guidance_strength'] = guidance_strength\n",
        "        results['timestamp'] = timestamp\n",
        "        results['evaluation_timestamp'] = datetime.now().isoformat()\n",
        "        results['num_images'] = recon_batch.shape[0]\n",
        "        \n",
        "        return results\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Error evaluating {exp_name}: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Results Management Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ===== RESULTS MANAGEMENT FUNCTIONS =====\n",
        "def save_results(results_dict, filename=None):\n",
        "    \"\"\"Save results to JSON file with proper serialization\"\"\"\n",
        "    if filename is None:\n",
        "        filename = RESULTS_FILE\n",
        "    \n",
        "    try:\n",
        "        # Convert numpy arrays and float32 to JSON-serializable types\n",
        "        def convert_for_json(obj):\n",
        "            if isinstance(obj, np.ndarray):\n",
        "                return obj.tolist()\n",
        "            elif isinstance(obj, np.float32):\n",
        "                return float(obj)\n",
        "            elif isinstance(obj, np.float64):\n",
        "                return float(obj)\n",
        "            elif isinstance(obj, np.int32):\n",
        "                return int(obj)\n",
        "            elif isinstance(obj, np.int64):\n",
        "                return int(obj)\n",
        "            elif isinstance(obj, dict):\n",
        "                return {key: convert_for_json(value) for key, value in obj.items()}\n",
        "            elif isinstance(obj, list):\n",
        "                return [convert_for_json(item) for item in obj]\n",
        "            else:\n",
        "                return obj\n",
        "        \n",
        "        # Convert all numpy types to JSON-serializable types\n",
        "        serializable_results = convert_for_json(results_dict)\n",
        "        \n",
        "        with open(filename, 'w') as f:\n",
        "            json.dump(serializable_results, f, indent=2)\n",
        "        print(f\"Results saved to: {filename}\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving results: {e}\")\n",
        "        return False\n",
        "\n",
        "def load_existing_results(filename=None):\n",
        "    \"\"\"Load existing results from JSON file\"\"\"\n",
        "    if filename is None:\n",
        "        filename = RESULTS_FILE\n",
        "    \n",
        "    if os.path.exists(filename):\n",
        "        try:\n",
        "            with open(filename, 'r') as f:\n",
        "                return json.load(f)\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading existing results: {e}\")\n",
        "            return {}\n",
        "    return {}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Main Evaluation Loop\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Starting evaluation of 34 experiments...\n",
            "Loaded 28 existing results\n",
            "\n",
            "============================================================\n",
            "EVALUATING: brain_scheduling_scale100000_str0.4_20251027_192430\n",
            "Directory: /home/kevin/Documents/ACV/Project/advanced-cv-project/outputs_all/subj01/brain_scheduling/100000/0.4/20251027_192430\n",
            "============================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading ground truth: 100%|██████████| 50/50 [00:00<00:00, 95.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GT batch shape: torch.Size([50, 3, 224, 224])\n",
            "Recon batch shape: torch.Size([250, 3, 224, 224])\n",
            "Running comprehensive evaluation...\n",
            "Detected 5 reconstructions per ground truth image\n",
            "Grouping 5 reconstructions per ground truth image\n",
            "  GT 0: Best SSIM = 0.3349 (reconstruction 3)\n",
            "  GT 1: Best SSIM = 0.4163 (reconstruction 3)\n",
            "  GT 2: Best SSIM = 0.7082 (reconstruction 0)\n",
            "  GT 3: Best SSIM = 0.4325 (reconstruction 3)\n",
            "  GT 4: Best SSIM = 0.1329 (reconstruction 4)\n",
            "  GT 5: Best SSIM = 0.6733 (reconstruction 0)\n",
            "  GT 6: Best SSIM = 0.2882 (reconstruction 4)\n",
            "  GT 7: Best SSIM = 0.2408 (reconstruction 1)\n",
            "  GT 8: Best SSIM = 0.5701 (reconstruction 3)\n",
            "  GT 9: Best SSIM = 0.3740 (reconstruction 1)\n",
            "  GT 10: Best SSIM = 0.6488 (reconstruction 2)\n",
            "  GT 11: Best SSIM = 0.5629 (reconstruction 0)\n",
            "  GT 12: Best SSIM = 0.4589 (reconstruction 1)\n",
            "  GT 13: Best SSIM = 0.3262 (reconstruction 3)\n",
            "  GT 14: Best SSIM = 0.6961 (reconstruction 1)\n",
            "  GT 15: Best SSIM = 0.5181 (reconstruction 0)\n",
            "  GT 16: Best SSIM = 0.8146 (reconstruction 2)\n",
            "  GT 17: Best SSIM = 0.4623 (reconstruction 1)\n",
            "  GT 18: Best SSIM = 0.5669 (reconstruction 0)\n",
            "  GT 19: Best SSIM = 0.6432 (reconstruction 3)\n",
            "  GT 20: Best SSIM = 0.6977 (reconstruction 1)\n",
            "  GT 21: Best SSIM = 0.4294 (reconstruction 2)\n",
            "  GT 22: Best SSIM = 0.7469 (reconstruction 1)\n",
            "  GT 23: Best SSIM = 0.5917 (reconstruction 3)\n",
            "  GT 24: Best SSIM = 0.3372 (reconstruction 1)\n",
            "  GT 25: Best SSIM = 0.6524 (reconstruction 1)\n",
            "  GT 26: Best SSIM = 0.6150 (reconstruction 1)\n",
            "  GT 27: Best SSIM = 0.5727 (reconstruction 0)\n",
            "  GT 28: Best SSIM = 0.3768 (reconstruction 1)\n",
            "  GT 29: Best SSIM = 0.2988 (reconstruction 2)\n",
            "  GT 30: Best SSIM = 0.3333 (reconstruction 0)\n",
            "  GT 31: Best SSIM = 0.3395 (reconstruction 0)\n",
            "  GT 32: Best SSIM = 0.2522 (reconstruction 1)\n",
            "  GT 33: Best SSIM = 0.3347 (reconstruction 2)\n",
            "  GT 34: Best SSIM = 0.5641 (reconstruction 2)\n",
            "  GT 35: Best SSIM = 0.4166 (reconstruction 2)\n",
            "  GT 36: Best SSIM = 0.3231 (reconstruction 4)\n",
            "  GT 37: Best SSIM = 0.4708 (reconstruction 1)\n",
            "  GT 38: Best SSIM = 0.4577 (reconstruction 4)\n",
            "  GT 39: Best SSIM = 0.3489 (reconstruction 2)\n",
            "  GT 40: Best SSIM = 0.2679 (reconstruction 1)\n",
            "  GT 41: Best SSIM = 0.4145 (reconstruction 2)\n",
            "  GT 42: Best SSIM = 0.6692 (reconstruction 3)\n",
            "  GT 43: Best SSIM = 0.2519 (reconstruction 0)\n",
            "  GT 44: Best SSIM = 0.2960 (reconstruction 4)\n",
            "  GT 45: Best SSIM = 0.4384 (reconstruction 3)\n",
            "  GT 46: Best SSIM = 0.5169 (reconstruction 0)\n",
            "  GT 47: Best SSIM = 0.5481 (reconstruction 1)\n",
            "  GT 48: Best SSIM = 0.3253 (reconstruction 0)\n",
            "  GT 49: Best SSIM = 0.2060 (reconstruction 0)\n",
            "Selected best reconstructions: torch.Size([50, 3, 224, 224])\n",
            "Starting comprehensive evaluation...\n",
            "Computing low-level metrics...\n",
            "Computing high-level metrics...\n",
            "Computing distance metrics...\n",
            "Results saved to: /home/kevin/Documents/ACV/Project/advanced-cv-project/evaluation_results.json\n",
            "Results saved for brain_scheduling_scale100000_str0.4_20251027_192430\n",
            "Skipping brain_scheduling_scale100000_str0.2_20251026_215211 (already evaluated)\n",
            "\n",
            "============================================================\n",
            "EVALUATING: brain_scheduling_scale100000_str0.1_20251027_200225\n",
            "Directory: /home/kevin/Documents/ACV/Project/advanced-cv-project/outputs_all/subj01/brain_scheduling/100000/0.1/20251027_200225\n",
            "============================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading ground truth: 100%|██████████| 50/50 [00:00<00:00, 97.86it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GT batch shape: torch.Size([50, 3, 224, 224])\n",
            "Recon batch shape: torch.Size([250, 3, 224, 224])\n",
            "Running comprehensive evaluation...\n",
            "Detected 5 reconstructions per ground truth image\n",
            "Grouping 5 reconstructions per ground truth image\n",
            "  GT 0: Best SSIM = 0.3483 (reconstruction 3)\n",
            "  GT 1: Best SSIM = 0.3895 (reconstruction 3)\n",
            "  GT 2: Best SSIM = 0.6607 (reconstruction 1)\n",
            "  GT 3: Best SSIM = 0.4164 (reconstruction 3)\n",
            "  GT 4: Best SSIM = 0.1218 (reconstruction 4)\n",
            "  GT 5: Best SSIM = 0.5453 (reconstruction 1)\n",
            "  GT 6: Best SSIM = 0.2935 (reconstruction 4)\n",
            "  GT 7: Best SSIM = 0.2642 (reconstruction 3)\n",
            "  GT 8: Best SSIM = 0.4816 (reconstruction 2)\n",
            "  GT 9: Best SSIM = 0.3694 (reconstruction 1)\n",
            "  GT 10: Best SSIM = 0.6263 (reconstruction 2)\n",
            "  GT 11: Best SSIM = 0.5287 (reconstruction 1)\n",
            "  GT 12: Best SSIM = 0.4798 (reconstruction 0)\n",
            "  GT 13: Best SSIM = 0.3192 (reconstruction 3)\n",
            "  GT 14: Best SSIM = 0.5968 (reconstruction 2)\n",
            "  GT 15: Best SSIM = 0.5132 (reconstruction 3)\n",
            "  GT 16: Best SSIM = 0.7682 (reconstruction 2)\n",
            "  GT 17: Best SSIM = 0.4731 (reconstruction 2)\n",
            "  GT 18: Best SSIM = 0.5398 (reconstruction 0)\n",
            "  GT 19: Best SSIM = 0.6153 (reconstruction 3)\n",
            "  GT 20: Best SSIM = 0.6840 (reconstruction 3)\n",
            "  GT 21: Best SSIM = 0.4190 (reconstruction 2)\n",
            "  GT 22: Best SSIM = 0.6595 (reconstruction 1)\n",
            "  GT 23: Best SSIM = 0.5701 (reconstruction 3)\n",
            "  GT 24: Best SSIM = 0.3532 (reconstruction 1)\n",
            "  GT 25: Best SSIM = 0.6524 (reconstruction 1)\n",
            "  GT 26: Best SSIM = 0.5772 (reconstruction 1)\n",
            "  GT 27: Best SSIM = 0.5098 (reconstruction 3)\n",
            "  GT 28: Best SSIM = 0.3834 (reconstruction 1)\n",
            "  GT 29: Best SSIM = 0.2973 (reconstruction 2)\n",
            "  GT 30: Best SSIM = 0.3102 (reconstruction 3)\n",
            "  GT 31: Best SSIM = 0.3296 (reconstruction 0)\n",
            "  GT 32: Best SSIM = 0.2568 (reconstruction 3)\n",
            "  GT 33: Best SSIM = 0.3018 (reconstruction 3)\n",
            "  GT 34: Best SSIM = 0.5517 (reconstruction 2)\n",
            "  GT 35: Best SSIM = 0.4022 (reconstruction 1)\n",
            "  GT 36: Best SSIM = 0.3266 (reconstruction 1)\n",
            "  GT 37: Best SSIM = 0.4679 (reconstruction 1)\n",
            "  GT 38: Best SSIM = 0.4877 (reconstruction 3)\n",
            "  GT 39: Best SSIM = 0.3638 (reconstruction 2)\n",
            "  GT 40: Best SSIM = 0.2455 (reconstruction 1)\n",
            "  GT 41: Best SSIM = 0.4009 (reconstruction 1)\n",
            "  GT 42: Best SSIM = 0.6662 (reconstruction 3)\n",
            "  GT 43: Best SSIM = 0.2326 (reconstruction 0)\n",
            "  GT 44: Best SSIM = 0.3113 (reconstruction 4)\n",
            "  GT 45: Best SSIM = 0.4188 (reconstruction 3)\n",
            "  GT 46: Best SSIM = 0.4966 (reconstruction 2)\n",
            "  GT 47: Best SSIM = 0.5433 (reconstruction 1)\n",
            "  GT 48: Best SSIM = 0.3281 (reconstruction 4)\n",
            "  GT 49: Best SSIM = 0.2078 (reconstruction 0)\n",
            "Selected best reconstructions: torch.Size([50, 3, 224, 224])\n",
            "Starting comprehensive evaluation...\n",
            "Computing low-level metrics...\n",
            "Computing high-level metrics...\n",
            "Computing distance metrics...\n",
            "Results saved to: /home/kevin/Documents/ACV/Project/advanced-cv-project/evaluation_results.json\n",
            "Results saved for brain_scheduling_scale100000_str0.1_20251027_200225\n",
            "\n",
            "============================================================\n",
            "EVALUATING: brain_scheduling_scale30000_str0.4_20251027_181755\n",
            "Directory: /home/kevin/Documents/ACV/Project/advanced-cv-project/outputs_all/subj01/brain_scheduling/30000/0.4/20251027_181755\n",
            "============================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading ground truth: 100%|██████████| 50/50 [00:00<00:00, 101.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GT batch shape: torch.Size([50, 3, 224, 224])\n",
            "Recon batch shape: torch.Size([250, 3, 224, 224])\n",
            "Running comprehensive evaluation...\n",
            "Detected 5 reconstructions per ground truth image\n",
            "Grouping 5 reconstructions per ground truth image\n",
            "  GT 0: Best SSIM = 0.3921 (reconstruction 1)\n",
            "  GT 1: Best SSIM = 0.5008 (reconstruction 1)\n",
            "  GT 2: Best SSIM = 0.7485 (reconstruction 1)\n",
            "  GT 3: Best SSIM = 0.4368 (reconstruction 3)\n",
            "  GT 4: Best SSIM = 0.1398 (reconstruction 0)\n",
            "  GT 5: Best SSIM = 0.6679 (reconstruction 0)\n",
            "  GT 6: Best SSIM = 0.3260 (reconstruction 0)\n",
            "  GT 7: Best SSIM = 0.2779 (reconstruction 3)\n",
            "  GT 8: Best SSIM = 0.5517 (reconstruction 2)\n",
            "  GT 9: Best SSIM = 0.3988 (reconstruction 2)\n",
            "  GT 10: Best SSIM = 0.6750 (reconstruction 2)\n",
            "  GT 11: Best SSIM = 0.5639 (reconstruction 4)\n",
            "  GT 12: Best SSIM = 0.5566 (reconstruction 3)\n",
            "  GT 13: Best SSIM = 0.4411 (reconstruction 4)\n",
            "  GT 14: Best SSIM = 0.5895 (reconstruction 1)\n",
            "  GT 15: Best SSIM = 0.5122 (reconstruction 3)\n",
            "  GT 16: Best SSIM = 0.7953 (reconstruction 2)\n",
            "  GT 17: Best SSIM = 0.5849 (reconstruction 1)\n",
            "  GT 18: Best SSIM = 0.5830 (reconstruction 1)\n",
            "  GT 19: Best SSIM = 0.6365 (reconstruction 4)\n",
            "  GT 20: Best SSIM = 0.7193 (reconstruction 1)\n",
            "  GT 21: Best SSIM = 0.3999 (reconstruction 3)\n",
            "  GT 22: Best SSIM = 0.6902 (reconstruction 4)\n",
            "  GT 23: Best SSIM = 0.6328 (reconstruction 2)\n",
            "  GT 24: Best SSIM = 0.3907 (reconstruction 1)\n",
            "  GT 25: Best SSIM = 0.6619 (reconstruction 4)\n",
            "  GT 26: Best SSIM = 0.6570 (reconstruction 3)\n",
            "  GT 27: Best SSIM = 0.5867 (reconstruction 1)\n",
            "  GT 28: Best SSIM = 0.3824 (reconstruction 1)\n",
            "  GT 29: Best SSIM = 0.3354 (reconstruction 2)\n",
            "  GT 30: Best SSIM = 0.3597 (reconstruction 3)\n",
            "  GT 31: Best SSIM = 0.3816 (reconstruction 0)\n",
            "  GT 32: Best SSIM = 0.3026 (reconstruction 4)\n",
            "  GT 33: Best SSIM = 0.3921 (reconstruction 0)\n",
            "  GT 34: Best SSIM = 0.5507 (reconstruction 1)\n",
            "  GT 35: Best SSIM = 0.4423 (reconstruction 2)\n",
            "  GT 36: Best SSIM = 0.3628 (reconstruction 4)\n",
            "  GT 37: Best SSIM = 0.5281 (reconstruction 1)\n",
            "  GT 38: Best SSIM = 0.5324 (reconstruction 3)\n",
            "  GT 39: Best SSIM = 0.4028 (reconstruction 3)\n",
            "  GT 40: Best SSIM = 0.2728 (reconstruction 2)\n",
            "  GT 41: Best SSIM = 0.4287 (reconstruction 2)\n",
            "  GT 42: Best SSIM = 0.7030 (reconstruction 4)\n",
            "  GT 43: Best SSIM = 0.2802 (reconstruction 4)\n",
            "  GT 44: Best SSIM = 0.3984 (reconstruction 2)\n",
            "  GT 45: Best SSIM = 0.4347 (reconstruction 2)\n",
            "  GT 46: Best SSIM = 0.5419 (reconstruction 1)\n",
            "  GT 47: Best SSIM = 0.6217 (reconstruction 4)\n",
            "  GT 48: Best SSIM = 0.3495 (reconstruction 0)\n",
            "  GT 49: Best SSIM = 0.2621 (reconstruction 2)\n",
            "Selected best reconstructions: torch.Size([50, 3, 224, 224])\n",
            "Starting comprehensive evaluation...\n",
            "Computing low-level metrics...\n",
            "Computing high-level metrics...\n",
            "Computing distance metrics...\n",
            "Results saved to: /home/kevin/Documents/ACV/Project/advanced-cv-project/evaluation_results.json\n",
            "Results saved for brain_scheduling_scale30000_str0.4_20251027_181755\n",
            "Skipping brain_scheduling_scale30000_str0.2_20251026_212457 (already evaluated)\n",
            "\n",
            "============================================================\n",
            "EVALUATING: brain_scheduling_scale30000_str0.1_20251027_185522\n",
            "Directory: /home/kevin/Documents/ACV/Project/advanced-cv-project/outputs_all/subj01/brain_scheduling/30000/0.1/20251027_185522\n",
            "============================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading ground truth: 100%|██████████| 50/50 [00:00<00:00, 104.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GT batch shape: torch.Size([50, 3, 224, 224])\n",
            "Recon batch shape: torch.Size([250, 3, 224, 224])\n",
            "Running comprehensive evaluation...\n",
            "Detected 5 reconstructions per ground truth image\n",
            "Grouping 5 reconstructions per ground truth image\n",
            "  GT 0: Best SSIM = 0.3991 (reconstruction 1)\n",
            "  GT 1: Best SSIM = 0.4875 (reconstruction 1)\n",
            "  GT 2: Best SSIM = 0.7549 (reconstruction 1)\n",
            "  GT 3: Best SSIM = 0.4356 (reconstruction 3)\n",
            "  GT 4: Best SSIM = 0.1397 (reconstruction 1)\n",
            "  GT 5: Best SSIM = 0.6478 (reconstruction 0)\n",
            "  GT 6: Best SSIM = 0.3244 (reconstruction 0)\n",
            "  GT 7: Best SSIM = 0.2810 (reconstruction 3)\n",
            "  GT 8: Best SSIM = 0.5402 (reconstruction 2)\n",
            "  GT 9: Best SSIM = 0.4048 (reconstruction 1)\n",
            "  GT 10: Best SSIM = 0.6213 (reconstruction 2)\n",
            "  GT 11: Best SSIM = 0.5763 (reconstruction 4)\n",
            "  GT 12: Best SSIM = 0.6192 (reconstruction 2)\n",
            "  GT 13: Best SSIM = 0.4383 (reconstruction 4)\n",
            "  GT 14: Best SSIM = 0.5271 (reconstruction 2)\n",
            "  GT 15: Best SSIM = 0.5182 (reconstruction 3)\n",
            "  GT 16: Best SSIM = 0.7503 (reconstruction 2)\n",
            "  GT 17: Best SSIM = 0.5248 (reconstruction 1)\n",
            "  GT 18: Best SSIM = 0.5803 (reconstruction 1)\n",
            "  GT 19: Best SSIM = 0.6352 (reconstruction 4)\n",
            "  GT 20: Best SSIM = 0.6676 (reconstruction 4)\n",
            "  GT 21: Best SSIM = 0.4085 (reconstruction 3)\n",
            "  GT 22: Best SSIM = 0.6568 (reconstruction 4)\n",
            "  GT 23: Best SSIM = 0.6368 (reconstruction 4)\n",
            "  GT 24: Best SSIM = 0.4073 (reconstruction 1)\n",
            "  GT 25: Best SSIM = 0.6665 (reconstruction 1)\n",
            "  GT 26: Best SSIM = 0.6594 (reconstruction 3)\n",
            "  GT 27: Best SSIM = 0.5502 (reconstruction 3)\n",
            "  GT 28: Best SSIM = 0.3721 (reconstruction 1)\n",
            "  GT 29: Best SSIM = 0.3329 (reconstruction 2)\n",
            "  GT 30: Best SSIM = 0.3718 (reconstruction 3)\n",
            "  GT 31: Best SSIM = 0.3808 (reconstruction 0)\n",
            "  GT 32: Best SSIM = 0.3075 (reconstruction 4)\n",
            "  GT 33: Best SSIM = 0.3796 (reconstruction 2)\n",
            "  GT 34: Best SSIM = 0.5547 (reconstruction 1)\n",
            "  GT 35: Best SSIM = 0.4416 (reconstruction 4)\n",
            "  GT 36: Best SSIM = 0.3666 (reconstruction 2)\n",
            "  GT 37: Best SSIM = 0.5289 (reconstruction 1)\n",
            "  GT 38: Best SSIM = 0.5260 (reconstruction 3)\n",
            "  GT 39: Best SSIM = 0.4058 (reconstruction 2)\n",
            "  GT 40: Best SSIM = 0.2705 (reconstruction 2)\n",
            "  GT 41: Best SSIM = 0.4128 (reconstruction 1)\n",
            "  GT 42: Best SSIM = 0.7185 (reconstruction 4)\n",
            "  GT 43: Best SSIM = 0.3021 (reconstruction 4)\n",
            "  GT 44: Best SSIM = 0.4011 (reconstruction 2)\n",
            "  GT 45: Best SSIM = 0.4306 (reconstruction 2)\n",
            "  GT 46: Best SSIM = 0.5474 (reconstruction 1)\n",
            "  GT 47: Best SSIM = 0.6105 (reconstruction 4)\n",
            "  GT 48: Best SSIM = 0.3459 (reconstruction 0)\n",
            "  GT 49: Best SSIM = 0.2776 (reconstruction 2)\n",
            "Selected best reconstructions: torch.Size([50, 3, 224, 224])\n",
            "Starting comprehensive evaluation...\n",
            "Computing low-level metrics...\n",
            "Computing high-level metrics...\n",
            "Computing distance metrics...\n",
            "Results saved to: /home/kevin/Documents/ACV/Project/advanced-cv-project/evaluation_results.json\n",
            "Results saved for brain_scheduling_scale30000_str0.1_20251027_185522\n",
            "\n",
            "============================================================\n",
            "EVALUATING: brain_scheduling_scale300000_str0.4_20251027_171904\n",
            "Directory: /home/kevin/Documents/ACV/Project/advanced-cv-project/outputs_all/subj01/brain_scheduling/300000/0.4/20251027_171904\n",
            "============================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading ground truth: 100%|██████████| 50/50 [00:00<00:00, 108.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GT batch shape: torch.Size([50, 3, 224, 224])\n",
            "Recon batch shape: torch.Size([250, 3, 224, 224])\n",
            "Running comprehensive evaluation...\n",
            "Detected 5 reconstructions per ground truth image\n",
            "Grouping 5 reconstructions per ground truth image\n",
            "  GT 0: Best SSIM = 0.2279 (reconstruction 2)\n",
            "  GT 1: Best SSIM = 0.3783 (reconstruction 0)\n",
            "  GT 2: Best SSIM = 0.7022 (reconstruction 1)\n",
            "  GT 3: Best SSIM = 0.4320 (reconstruction 0)\n",
            "  GT 4: Best SSIM = 0.1278 (reconstruction 2)\n",
            "  GT 5: Best SSIM = 0.6933 (reconstruction 0)\n",
            "  GT 6: Best SSIM = 0.2672 (reconstruction 0)\n",
            "  GT 7: Best SSIM = 0.1942 (reconstruction 1)\n",
            "  GT 8: Best SSIM = 0.5368 (reconstruction 0)\n",
            "  GT 9: Best SSIM = 0.3513 (reconstruction 1)\n",
            "  GT 10: Best SSIM = 0.6132 (reconstruction 1)\n",
            "  GT 11: Best SSIM = 0.5341 (reconstruction 1)\n",
            "  GT 12: Best SSIM = 0.4269 (reconstruction 1)\n",
            "  GT 13: Best SSIM = 0.3070 (reconstruction 2)\n",
            "  GT 14: Best SSIM = 0.6416 (reconstruction 2)\n",
            "  GT 15: Best SSIM = 0.5617 (reconstruction 0)\n",
            "  GT 16: Best SSIM = 0.7544 (reconstruction 1)\n",
            "  GT 17: Best SSIM = 0.5700 (reconstruction 1)\n",
            "  GT 18: Best SSIM = 0.5756 (reconstruction 0)\n",
            "  GT 19: Best SSIM = 0.5384 (reconstruction 2)\n",
            "  GT 20: Best SSIM = 0.6643 (reconstruction 1)\n",
            "  GT 21: Best SSIM = 0.3637 (reconstruction 3)\n",
            "  GT 22: Best SSIM = 0.7315 (reconstruction 2)\n",
            "  GT 23: Best SSIM = 0.5690 (reconstruction 1)\n",
            "  GT 24: Best SSIM = 0.3018 (reconstruction 1)\n",
            "  GT 25: Best SSIM = 0.6277 (reconstruction 1)\n",
            "  GT 26: Best SSIM = 0.5465 (reconstruction 0)\n",
            "  GT 27: Best SSIM = 0.5320 (reconstruction 0)\n",
            "  GT 28: Best SSIM = 0.3705 (reconstruction 1)\n",
            "  GT 29: Best SSIM = 0.2826 (reconstruction 1)\n",
            "  GT 30: Best SSIM = 0.3729 (reconstruction 1)\n",
            "  GT 31: Best SSIM = 0.3102 (reconstruction 3)\n",
            "  GT 32: Best SSIM = 0.2494 (reconstruction 1)\n",
            "  GT 33: Best SSIM = 0.3025 (reconstruction 0)\n",
            "  GT 34: Best SSIM = 0.5350 (reconstruction 2)\n",
            "  GT 35: Best SSIM = 0.4137 (reconstruction 0)\n",
            "  GT 36: Best SSIM = 0.3425 (reconstruction 1)\n",
            "  GT 37: Best SSIM = 0.4430 (reconstruction 1)\n",
            "  GT 38: Best SSIM = 0.3944 (reconstruction 3)\n",
            "  GT 39: Best SSIM = 0.3087 (reconstruction 0)\n",
            "  GT 40: Best SSIM = 0.1966 (reconstruction 0)\n",
            "  GT 41: Best SSIM = 0.3925 (reconstruction 1)\n",
            "  GT 42: Best SSIM = 0.6610 (reconstruction 2)\n",
            "  GT 43: Best SSIM = 0.1906 (reconstruction 0)\n",
            "  GT 44: Best SSIM = 0.2279 (reconstruction 0)\n",
            "  GT 45: Best SSIM = 0.3723 (reconstruction 4)\n",
            "  GT 46: Best SSIM = 0.5306 (reconstruction 0)\n",
            "  GT 47: Best SSIM = 0.4950 (reconstruction 1)\n",
            "  GT 48: Best SSIM = 0.2708 (reconstruction 0)\n",
            "  GT 49: Best SSIM = 0.2243 (reconstruction 0)\n",
            "Selected best reconstructions: torch.Size([50, 3, 224, 224])\n",
            "Starting comprehensive evaluation...\n",
            "Computing low-level metrics...\n",
            "Computing high-level metrics...\n",
            "Computing distance metrics...\n",
            "Results saved to: /home/kevin/Documents/ACV/Project/advanced-cv-project/evaluation_results.json\n",
            "Results saved for brain_scheduling_scale300000_str0.4_20251027_171904\n",
            "Skipping brain_scheduling_scale300000_str0.2_20251026_205738 (already evaluated)\n",
            "\n",
            "============================================================\n",
            "EVALUATING: brain_scheduling_scale300000_str0.1_20251027_175307\n",
            "Directory: /home/kevin/Documents/ACV/Project/advanced-cv-project/outputs_all/subj01/brain_scheduling/300000/0.1/20251027_175307\n",
            "============================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading ground truth: 100%|██████████| 50/50 [00:00<00:00, 95.83it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GT batch shape: torch.Size([50, 3, 224, 224])\n",
            "Recon batch shape: torch.Size([250, 3, 224, 224])\n",
            "Running comprehensive evaluation...\n",
            "Detected 5 reconstructions per ground truth image\n",
            "Grouping 5 reconstructions per ground truth image\n",
            "  GT 0: Best SSIM = 0.2603 (reconstruction 3)\n",
            "  GT 1: Best SSIM = 0.3485 (reconstruction 0)\n",
            "  GT 2: Best SSIM = 0.6378 (reconstruction 1)\n",
            "  GT 3: Best SSIM = 0.4048 (reconstruction 0)\n",
            "  GT 4: Best SSIM = 0.1284 (reconstruction 4)\n",
            "  GT 5: Best SSIM = 0.5489 (reconstruction 2)\n",
            "  GT 6: Best SSIM = 0.2274 (reconstruction 0)\n",
            "  GT 7: Best SSIM = 0.2078 (reconstruction 3)\n",
            "  GT 8: Best SSIM = 0.4985 (reconstruction 4)\n",
            "  GT 9: Best SSIM = 0.3271 (reconstruction 1)\n",
            "  GT 10: Best SSIM = 0.5986 (reconstruction 2)\n",
            "  GT 11: Best SSIM = 0.5337 (reconstruction 1)\n",
            "  GT 12: Best SSIM = 0.3960 (reconstruction 1)\n",
            "  GT 13: Best SSIM = 0.2958 (reconstruction 2)\n",
            "  GT 14: Best SSIM = 0.5538 (reconstruction 2)\n",
            "  GT 15: Best SSIM = 0.5090 (reconstruction 2)\n",
            "  GT 16: Best SSIM = 0.7576 (reconstruction 2)\n",
            "  GT 17: Best SSIM = 0.4620 (reconstruction 1)\n",
            "  GT 18: Best SSIM = 0.4908 (reconstruction 3)\n",
            "  GT 19: Best SSIM = 0.5201 (reconstruction 3)\n",
            "  GT 20: Best SSIM = 0.5840 (reconstruction 4)\n",
            "  GT 21: Best SSIM = 0.3555 (reconstruction 1)\n",
            "  GT 22: Best SSIM = 0.7256 (reconstruction 2)\n",
            "  GT 23: Best SSIM = 0.5507 (reconstruction 1)\n",
            "  GT 24: Best SSIM = 0.2806 (reconstruction 1)\n",
            "  GT 25: Best SSIM = 0.6173 (reconstruction 2)\n",
            "  GT 26: Best SSIM = 0.4825 (reconstruction 3)\n",
            "  GT 27: Best SSIM = 0.4037 (reconstruction 0)\n",
            "  GT 28: Best SSIM = 0.3374 (reconstruction 1)\n",
            "  GT 29: Best SSIM = 0.2652 (reconstruction 2)\n",
            "  GT 30: Best SSIM = 0.2933 (reconstruction 2)\n",
            "  GT 31: Best SSIM = 0.2728 (reconstruction 3)\n",
            "  GT 32: Best SSIM = 0.2295 (reconstruction 1)\n",
            "  GT 33: Best SSIM = 0.2611 (reconstruction 0)\n",
            "  GT 34: Best SSIM = 0.5438 (reconstruction 2)\n",
            "  GT 35: Best SSIM = 0.3768 (reconstruction 2)\n",
            "  GT 36: Best SSIM = 0.3188 (reconstruction 4)\n",
            "  GT 37: Best SSIM = 0.4324 (reconstruction 2)\n",
            "  GT 38: Best SSIM = 0.3757 (reconstruction 3)\n",
            "  GT 39: Best SSIM = 0.3187 (reconstruction 0)\n",
            "  GT 40: Best SSIM = 0.2232 (reconstruction 1)\n",
            "  GT 41: Best SSIM = 0.3919 (reconstruction 3)\n",
            "  GT 42: Best SSIM = 0.5663 (reconstruction 3)\n",
            "  GT 43: Best SSIM = 0.1545 (reconstruction 0)\n",
            "  GT 44: Best SSIM = 0.2257 (reconstruction 0)\n",
            "  GT 45: Best SSIM = 0.3706 (reconstruction 3)\n",
            "  GT 46: Best SSIM = 0.4576 (reconstruction 0)\n",
            "  GT 47: Best SSIM = 0.4547 (reconstruction 2)\n",
            "  GT 48: Best SSIM = 0.2401 (reconstruction 2)\n",
            "  GT 49: Best SSIM = 0.2323 (reconstruction 4)\n",
            "Selected best reconstructions: torch.Size([50, 3, 224, 224])\n",
            "Starting comprehensive evaluation...\n",
            "Computing low-level metrics...\n",
            "Computing high-level metrics...\n",
            "Computing distance metrics...\n",
            "Results saved to: /home/kevin/Documents/ACV/Project/advanced-cv-project/evaluation_results.json\n",
            "Results saved for brain_scheduling_scale300000_str0.1_20251027_175307\n",
            "Skipping cp_4096_v1_with_z_scale8000_str0.2_20251026_162044 (already evaluated)\n",
            "Skipping cp_4096_v1_with_z_scale3000_str0.4_20251026_085458 (already evaluated)\n",
            "Skipping cp_4096_v1_with_z_scale3000_str0.2_20251026_080314 (already evaluated)\n",
            "Skipping cp_4096_v1_with_z_scale3000_str0.1_20251026_083046 (already evaluated)\n",
            "Skipping cp_4096_v1_with_z_scale100000_str0.2_20251026_152601 (already evaluated)\n",
            "Skipping cp_4096_v1_with_z_scale3000000_str0.4_20251026_043948 (already evaluated)\n",
            "Skipping cp_4096_v1_with_z_scale3000000_str0.2_20251026_034747 (already evaluated)\n",
            "Skipping cp_4096_v1_with_z_scale3000000_str0.1_20251026_041544 (already evaluated)\n",
            "Skipping cp_4096_v1_with_z_scale200000_str0.2_20251026_155320 (already evaluated)\n",
            "Skipping cp_4096_v1_with_z_scale30000_str0.4_20251026_072950 (already evaluated)\n",
            "Skipping cp_4096_v1_with_z_scale30000_str0.2_20251026_063805 (already evaluated)\n",
            "Skipping cp_4096_v1_with_z_scale30000_str0.1_20251026_070537 (already evaluated)\n",
            "Skipping cp_4096_v1_with_z_scale300000_str0.4_20251026_060443 (already evaluated)\n",
            "Skipping cp_4096_v1_with_z_scale300000_str0.2_20251026_051305 (already evaluated)\n",
            "Skipping cp_4096_v1_with_z_scale300000_str0.1_20251026_054035 (already evaluated)\n",
            "Skipping cp_4096_v1_no_z_scale100000_str0.4_20251027_095725 (already evaluated)\n",
            "Skipping cp_4096_v1_no_z_scale100000_str0.2_20251027_090137 (already evaluated)\n",
            "Skipping cp_4096_v1_no_z_scale100000_str0.1_20251027_093119 (already evaluated)\n",
            "Skipping cp_4096_v1_no_z_scale30000_str0.4_20251027_082536 (already evaluated)\n",
            "Skipping cp_4096_v1_no_z_scale30000_str0.2_20251027_073001 (already evaluated)\n",
            "Skipping cp_4096_v1_no_z_scale30000_str0.1_20251027_075937 (already evaluated)\n",
            "Skipping cp_4096_v1_no_z_scale300000_str0.4_20251027_065405 (already evaluated)\n",
            "Skipping cp_4096_v1_no_z_scale300000_str0.2_20251027_055838 (already evaluated)\n",
            "Skipping cp_4096_v1_no_z_scale300000_str2.0_20251026_143307 (already evaluated)\n",
            "Skipping cp_4096_v1_no_z_scale300000_str0.1_20251027_062810 (already evaluated)\n",
            "\n",
            "============================================================\n",
            "EVALUATION COMPLETE\n",
            "============================================================\n",
            "Total experiments: 34\n",
            "Completed: 6\n",
            "Failed: 0\n",
            "Skipped: 28\n",
            "Total results: 34\n",
            "Results saved to: /home/kevin/Documents/ACV/Project/advanced-cv-project/evaluation_results.json\n"
          ]
        }
      ],
      "source": [
        "# ===== MAIN EVALUATION LOOP =====\n",
        "def run_evaluation_loop():\n",
        "    \"\"\"Run the main evaluation loop\"\"\"\n",
        "    print(f\"\\nStarting evaluation of {len(experimental_dirs)} experiments...\")\n",
        "    \n",
        "    # Load existing results\n",
        "    all_results = load_existing_results()\n",
        "    print(f\"Loaded {len(all_results)} existing results\")\n",
        "    \n",
        "    # Track progress\n",
        "    completed = 0\n",
        "    failed = 0\n",
        "    \n",
        "    for i, exp_dir in enumerate(experimental_dirs):\n",
        "        # Create experiment name from directory path\n",
        "        path_parts = exp_dir.parts\n",
        "        method_name = path_parts[-4]\n",
        "        guidance_scale = path_parts[-3]\n",
        "        guidance_strength = path_parts[-2]\n",
        "        timestamp = path_parts[-1]\n",
        "        \n",
        "        exp_name = f\"{method_name}_scale{guidance_scale}_str{guidance_strength}_{timestamp}\"\n",
        "        \n",
        "        # Skip if already evaluated\n",
        "        if exp_name in all_results:\n",
        "            print(f\"Skipping {exp_name} (already evaluated)\")\n",
        "            continue\n",
        "        \n",
        "        # Evaluate this experiment\n",
        "        results = evaluate_single_experiment(exp_dir, exp_name)\n",
        "        \n",
        "        if results is not None:\n",
        "            all_results[exp_name] = results\n",
        "            completed += 1\n",
        "            \n",
        "            # Save results after each experiment\n",
        "            if save_results(all_results):\n",
        "                print(f\"Results saved for {exp_name}\")\n",
        "            else:\n",
        "                print(f\"Failed to save results for {exp_name}\")\n",
        "        else:\n",
        "            failed += 1\n",
        "            print(f\"Failed to evaluate {exp_name}\")\n",
        "    \n",
        "    # Final summary\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"EVALUATION COMPLETE\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"Total experiments: {len(experimental_dirs)}\")\n",
        "    print(f\"Completed: {completed}\")\n",
        "    print(f\"Failed: {failed}\")\n",
        "    print(f\"Skipped: {len(experimental_dirs) - completed - failed}\")\n",
        "    print(f\"Total results: {len(all_results)}\")\n",
        "    print(f\"Results saved to: {RESULTS_FILE}\")\n",
        "    \n",
        "    return all_results\n",
        "\n",
        "# Run the evaluation\n",
        "all_results = run_evaluation_loop()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Results Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Analyzing 34 experimental results...\n"
          ]
        }
      ],
      "source": [
        "# ===== RESULTS ANALYSIS =====\n",
        "def analyze_results(results_dict):\n",
        "    \"\"\"Analyze and compare all experimental results\"\"\"\n",
        "    if not results_dict:\n",
        "        print(\"No results to analyze!\")\n",
        "        return None\n",
        "    \n",
        "    print(f\"Analyzing {len(results_dict)} experimental results...\")\n",
        "    \n",
        "    # Create comparison table\n",
        "    comparison_data = []\n",
        "    for exp_name, results in results_dict.items():\n",
        "        row = {\n",
        "            'Experiment': exp_name,\n",
        "            'Method': results.get('method_name', 'Unknown'),\n",
        "            'Guidance Scale': results.get('guidance_scale', 'Unknown'),\n",
        "            'Guidance Strength': results.get('guidance_strength', 'Unknown'),\n",
        "            'Timestamp': results.get('timestamp', 'Unknown'),\n",
        "            'Num Images': results.get('num_images', 0)\n",
        "        }\n",
        "        \n",
        "        # Add metric results\n",
        "        if 'low_level' in results:\n",
        "            row['SSIM'] = results['low_level'].get('SSIM', {}).get('mean', 0)\n",
        "            row['PixCorr'] = results['low_level'].get('PixCorr', {}).get('mean', 0)\n",
        "        \n",
        "        if 'high_level' in results:\n",
        "            row['AlexNet-2'] = results['high_level'].get('AlexNet-2', 0)\n",
        "            row['AlexNet-5'] = results['high_level'].get('AlexNet-5', 0)\n",
        "            row['CLIP'] = results['high_level'].get('CLIP', 0)\n",
        "            row['InceptionV3'] = results['high_level'].get('InceptionV3', 0)\n",
        "        \n",
        "        if 'distance' in results:\n",
        "            row['EffNet-B'] = results['distance'].get('EffNet-B', 0)\n",
        "            row['SwAV'] = results['distance'].get('SwAV', 0)\n",
        "        \n",
        "        if 'image_quality' in results:\n",
        "            row['IS'] = results['image_quality'].get('IS', 0)\n",
        "            row['FID'] = results['image_quality'].get('FID', 0)\n",
        "        \n",
        "        # Add selection information if available\n",
        "        if 'selection_info' in results:\n",
        "            row['Best SSIM Mean'] = results['selection_info'].get('mean_best_score', 0)\n",
        "            row['Best SSIM Std'] = results['selection_info'].get('std_best_score', 0)\n",
        "            row['Reconstructions per GT'] = results['selection_info'].get('reconstructions_per_gt', 0)\n",
        "        \n",
        "        comparison_data.append(row)\n",
        "    \n",
        "    return comparison_data\n",
        "\n",
        "# Analyze results\n",
        "comparison_data = analyze_results(all_results)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Results Display and Export\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Results Comparison Table:\n",
            "                                           Experiment            Method Guidance Scale Guidance Strength       Timestamp  Num Images     SSIM  PixCorr  AlexNet-2  AlexNet-5  CLIP  InceptionV3  EffNet-B     SwAV\n",
            "  brain_scheduling_scale100000_str0.2_20251026_215211  brain_scheduling         100000               0.2 20251026_215211         250 0.450158 0.142831       18.0       28.0  18.0         28.0  0.861243 0.055953\n",
            "   brain_scheduling_scale30000_str0.2_20251026_212457  brain_scheduling          30000               0.2 20251026_212457         250 0.482724 0.140103        8.0       20.0  24.0         24.0  0.870597 0.067196\n",
            "  brain_scheduling_scale300000_str0.2_20251026_205738  brain_scheduling         300000               0.2 20251026_205738         250 0.413019 0.149849       26.0       16.0  22.0         28.0  0.915376 0.056867\n",
            "   cp_4096_v1_with_z_scale8000_str0.2_20251026_162044 cp_4096_v1_with_z           8000               0.2 20251026_162044         250 0.484636 0.143064        2.0       14.0  20.0         26.0  0.856665 0.061028\n",
            "   cp_4096_v1_with_z_scale3000_str0.4_20251026_085458 cp_4096_v1_with_z           3000               0.4 20251026_085458         250 0.505253 0.137847       10.0       18.0  22.0         14.0  0.866346 0.073173\n",
            "   cp_4096_v1_with_z_scale3000_str0.2_20251026_080314 cp_4096_v1_with_z           3000               0.2 20251026_080314         250 0.502729 0.132827       10.0       16.0  20.0         18.0  0.870167 0.072581\n",
            "   cp_4096_v1_with_z_scale3000_str0.1_20251026_083046 cp_4096_v1_with_z           3000               0.1 20251026_083046         250 0.502500 0.131097        8.0       12.0  18.0         20.0  0.862148 0.071865\n",
            " cp_4096_v1_with_z_scale100000_str0.2_20251026_152601 cp_4096_v1_with_z         100000               0.2 20251026_152601         250 0.418234 0.172002       20.0       30.0  24.0         32.0  0.856870 0.055978\n",
            "cp_4096_v1_with_z_scale3000000_str0.4_20251026_043948 cp_4096_v1_with_z        3000000               0.4 20251026_043948         250 0.374513 0.131653       12.0       12.0   2.0          8.0  0.915605 0.077845\n",
            "cp_4096_v1_with_z_scale3000000_str0.2_20251026_034747 cp_4096_v1_with_z        3000000               0.2 20251026_034747         250 0.370918 0.135190       10.0       12.0   4.0          4.0  0.900705 0.079898\n",
            "cp_4096_v1_with_z_scale3000000_str0.1_20251026_041544 cp_4096_v1_with_z        3000000               0.1 20251026_041544         250 0.369243 0.136308        8.0        6.0   4.0          4.0  0.922487 0.080261\n",
            " cp_4096_v1_with_z_scale200000_str0.2_20251026_155320 cp_4096_v1_with_z         200000               0.2 20251026_155320         250 0.407639 0.128202       26.0       28.0  16.0         26.0  0.903038 0.054608\n",
            "  cp_4096_v1_with_z_scale30000_str0.4_20251026_072950 cp_4096_v1_with_z          30000               0.4 20251026_072950         250 0.459741 0.139867       12.0       22.0  24.0         30.0  0.898475 0.056871\n",
            "  cp_4096_v1_with_z_scale30000_str0.2_20251026_063805 cp_4096_v1_with_z          30000               0.2 20251026_063805         250 0.444557 0.141395       18.0       18.0  26.0         24.0  0.877387 0.057573\n",
            "  cp_4096_v1_with_z_scale30000_str0.1_20251026_070537 cp_4096_v1_with_z          30000               0.1 20251026_070537         250 0.438753 0.139479       10.0       20.0  18.0         22.0  0.885270 0.059519\n",
            " cp_4096_v1_with_z_scale300000_str0.4_20251026_060443 cp_4096_v1_with_z         300000               0.4 20251026_060443         250 0.444955 0.150701       32.0       30.0  16.0         30.0  0.918119 0.053656\n",
            " cp_4096_v1_with_z_scale300000_str0.2_20251026_051305 cp_4096_v1_with_z         300000               0.2 20251026_051305         250 0.405739 0.144779       26.0       32.0  18.0         22.0  0.901337 0.056269\n",
            " cp_4096_v1_with_z_scale300000_str0.1_20251026_054035 cp_4096_v1_with_z         300000               0.1 20251026_054035         250 0.383680 0.135764       24.0       20.0  22.0         22.0  0.881281 0.057640\n",
            "   cp_4096_v1_no_z_scale300000_str2.0_20251026_143307   cp_4096_v1_no_z         300000               2.0 20251026_143307         250 0.467473 0.135805       36.0       32.0  20.0         22.0  0.895297 0.046909\n",
            "   cp_4096_v1_no_z_scale100000_str0.4_20251027_095725   cp_4096_v1_no_z         100000               0.4 20251027_095725         250 0.402087 0.069599       28.0       42.0  22.0         26.0  0.889719 0.055213\n",
            "   cp_4096_v1_no_z_scale100000_str0.2_20251027_090137   cp_4096_v1_no_z         100000               0.2 20251027_090137         250 0.370177 0.055827       20.0       24.0  36.0         26.0  0.894072 0.062400\n",
            "   cp_4096_v1_no_z_scale100000_str0.1_20251027_093119   cp_4096_v1_no_z         100000               0.1 20251027_093119         250 0.354205 0.042960       18.0       18.0  20.0         24.0  0.901198 0.067444\n",
            "    cp_4096_v1_no_z_scale30000_str0.4_20251027_082536   cp_4096_v1_no_z          30000               0.4 20251027_082536         250 0.378094 0.068646        8.0       16.0  16.0         20.0  0.883963 0.066808\n",
            "    cp_4096_v1_no_z_scale30000_str0.2_20251027_073001   cp_4096_v1_no_z          30000               0.2 20251027_073001         250 0.366766 0.067134       10.0       20.0  18.0         24.0  0.932657 0.062866\n",
            "    cp_4096_v1_no_z_scale30000_str0.1_20251027_075937   cp_4096_v1_no_z          30000               0.1 20251027_075937         250 0.356995 0.053860        4.0       10.0  14.0         30.0  0.891862 0.063117\n",
            "   cp_4096_v1_no_z_scale300000_str0.4_20251027_065405   cp_4096_v1_no_z         300000               0.4 20251027_065405         250 0.434971 0.124078       38.0       36.0  18.0         24.0  0.909298 0.048623\n",
            "   cp_4096_v1_no_z_scale300000_str0.2_20251027_055838   cp_4096_v1_no_z         300000               0.2 20251027_055838         250 0.379959 0.085140       30.0       42.0  20.0         26.0  0.904031 0.045608\n",
            "   cp_4096_v1_no_z_scale300000_str0.1_20251027_062810   cp_4096_v1_no_z         300000               0.1 20251027_062810         250 0.343243 0.047950       22.0       44.0  20.0         18.0  0.907037 0.054901\n",
            "  brain_scheduling_scale100000_str0.4_20251027_192430  brain_scheduling         100000               0.4 20251027_192430         250 0.459262 0.137713       14.0       26.0  16.0         26.0  0.899956 0.061024\n",
            "  brain_scheduling_scale100000_str0.1_20251027_200225  brain_scheduling         100000               0.1 20251027_200225         250 0.442125 0.135882       16.0       22.0  22.0         24.0  0.891169 0.063713\n",
            "   brain_scheduling_scale30000_str0.4_20251027_181755  brain_scheduling          30000               0.4 20251027_181755         250 0.487658 0.154352        8.0       16.0  24.0         20.0  0.866552 0.063092\n",
            "   brain_scheduling_scale30000_str0.1_20251027_185522  brain_scheduling          30000               0.1 20251027_185522         250 0.482892 0.139403       12.0       22.0  24.0         20.0  0.918197 0.065199\n",
            "  brain_scheduling_scale300000_str0.4_20251027_171904  brain_scheduling         300000               0.4 20251027_171904         250 0.433151 0.160998       28.0       34.0  22.0         30.0  0.873411 0.056913\n",
            "  brain_scheduling_scale300000_str0.1_20251027_175307  brain_scheduling         300000               0.1 20251027_175307         250 0.400985 0.146638       24.0       18.0  18.0         26.0  0.902263 0.056410\n",
            "\n",
            "Comparison table saved to: /home/kevin/Documents/ACV/Project/advanced-cv-project/experimental_comparison.csv\n",
            "\n",
            "Best SSIM by method:\n",
            "  brain_scheduling: brain_scheduling_scale30000_str0.4_20251027_181755 (SSIM: 0.4877)\n",
            "  cp_4096_v1_with_z: cp_4096_v1_with_z_scale3000_str0.4_20251026_085458 (SSIM: 0.5053)\n",
            "  cp_4096_v1_no_z: cp_4096_v1_no_z_scale300000_str2.0_20251026_143307 (SSIM: 0.4675)\n",
            "\n",
            "Best PixCorr by method:\n",
            "  brain_scheduling: brain_scheduling_scale300000_str0.4_20251027_171904 (PixCorr: 0.1610)\n",
            "  cp_4096_v1_with_z: cp_4096_v1_with_z_scale100000_str0.2_20251026_152601 (PixCorr: 0.1720)\n",
            "  cp_4096_v1_no_z: cp_4096_v1_no_z_scale300000_str2.0_20251026_143307 (PixCorr: 0.1358)\n",
            "\n",
            "Summary by method:\n",
            "  brain_scheduling: 9 experiments\n",
            "  cp_4096_v1_with_z: 15 experiments\n",
            "  cp_4096_v1_no_z: 10 experiments\n",
            "\n",
            "All results saved to: /home/kevin/Documents/ACV/Project/advanced-cv-project/evaluation_results.json\n",
            "Comparison table saved to: /home/kevin/Documents/ACV/Project/advanced-cv-project/experimental_comparison.csv\n"
          ]
        }
      ],
      "source": [
        "# ===== RESULTS DISPLAY AND EXPORT =====\n",
        "if comparison_data:\n",
        "    # Create DataFrame\n",
        "    df = pd.DataFrame(comparison_data)\n",
        "    print(f\"\\nResults Comparison Table:\")\n",
        "    print(df.to_string(index=False))\n",
        "    \n",
        "    # Save comparison table\n",
        "    comparison_file = f'{PROJECT_ROOT}/experimental_comparison.csv'\n",
        "    df.to_csv(comparison_file, index=False)\n",
        "    print(f\"\\nComparison table saved to: {comparison_file}\")\n",
        "    \n",
        "    # Find best performing experiments by method\n",
        "    if 'SSIM' in df.columns:\n",
        "        print(f\"\\nBest SSIM by method:\")\n",
        "        for method in df['Method'].unique():\n",
        "            method_df = df[df['Method'] == method]\n",
        "            if not method_df.empty and 'SSIM' in method_df.columns:\n",
        "                best_ssim = method_df.loc[method_df['SSIM'].idxmax()]\n",
        "                print(f\"  {method}: {best_ssim['Experiment']} (SSIM: {best_ssim['SSIM']:.4f})\")\n",
        "    \n",
        "    if 'PixCorr' in df.columns:\n",
        "        print(f\"\\nBest PixCorr by method:\")\n",
        "        for method in df['Method'].unique():\n",
        "            method_df = df[df['Method'] == method]\n",
        "            if not method_df.empty and 'PixCorr' in method_df.columns:\n",
        "                best_pixcorr = method_df.loc[method_df['PixCorr'].idxmax()]\n",
        "                print(f\"  {method}: {best_pixcorr['Experiment']} (PixCorr: {best_pixcorr['PixCorr']:.4f})\")\n",
        "    \n",
        "    # Show selection information if available\n",
        "    if 'Best SSIM Mean' in df.columns:\n",
        "        print(f\"\\nBest SSIM Selection Results:\")\n",
        "        for method in df['Method'].unique():\n",
        "            method_df = df[df['Method'] == method]\n",
        "            if not method_df.empty and 'Best SSIM Mean' in method_df.columns:\n",
        "                best_selection = method_df.loc[method_df['Best SSIM Mean'].idxmax()]\n",
        "                print(f\"  {method}: {best_selection['Experiment']} (Best SSIM: {best_selection['Best SSIM Mean']:.4f} ± {best_selection['Best SSIM Std']:.4f})\")\n",
        "    \n",
        "    # Summary by method\n",
        "    print(f\"\\nSummary by method:\")\n",
        "    for method in df['Method'].unique():\n",
        "        method_df = df[df['Method'] == method]\n",
        "        print(f\"  {method}: {len(method_df)} experiments\")\n",
        "    \n",
        "    print(f\"\\nAll results saved to: {RESULTS_FILE}\")\n",
        "    print(f\"Comparison table saved to: {comparison_file}\")\n",
        "else:\n",
        "    print(\"No results to display!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing individual metrics on sample reconstruction...\n",
            "Recon batch shape: torch.Size([25, 3, 224, 224])\n",
            "\n",
            "Testing metrics on 25 sample images...\n",
            "\n",
            "Testing AlexNet features...\n",
            "AlexNet-2 features shape: torch.Size([25, 32448])\n",
            "AlexNet-5 features shape: torch.Size([25, 9216])\n",
            "\n",
            "Testing InceptionV3 features...\n",
            "InceptionV3 features shape: torch.Size([25, 2048])\n",
            "\n",
            "Testing EfficientNet features...\n",
            "EfficientNet features shape: torch.Size([25, 1000])\n",
            "\n",
            "Individual metric testing completed!\n"
          ]
        }
      ],
      "source": [
        "# ===== INDIVIDUAL METRIC TESTING =====\n",
        "# Test individual metrics on a sample reconstruction (if available)\n",
        "if experimental_dirs and len(experimental_dirs) > 0:\n",
        "    print(\"Testing individual metrics on sample reconstruction...\")\n",
        "    \n",
        "    # Load a sample reconstruction\n",
        "    sample_dir = experimental_dirs[0]\n",
        "    sample_recon = load_reconstruction_images(sample_dir, max_images=5)\n",
        "    \n",
        "    if sample_recon is not None:\n",
        "        print(f\"\\nTesting metrics on {sample_recon.shape[0]} sample images...\")\n",
        "        \n",
        "        # Test AlexNet features\n",
        "        print(\"\\nTesting AlexNet features...\")\n",
        "        alexnet2_feat = alexnet_metrics.extract_features(sample_recon, layer=2)\n",
        "        alexnet5_feat = alexnet_metrics.extract_features(sample_recon, layer=5)\n",
        "        print(f\"AlexNet-2 features shape: {alexnet2_feat.shape}\")\n",
        "        print(f\"AlexNet-5 features shape: {alexnet5_feat.shape}\")\n",
        "        \n",
        "        # Test InceptionV3 features\n",
        "        print(\"\\nTesting InceptionV3 features...\")\n",
        "        inception_feat = inception_metrics.extract_features(sample_recon)\n",
        "        print(f\"InceptionV3 features shape: {inception_feat.shape}\")\n",
        "        \n",
        "        # Test EfficientNet features\n",
        "        print(\"\\nTesting EfficientNet features...\")\n",
        "        effnet_feat = effnet_dist.extract_features(sample_recon)\n",
        "        print(f\"EfficientNet features shape: {effnet_feat.shape}\")\n",
        "        \n",
        "        print(\"\\nIndividual metric testing completed!\")\n",
        "    else:\n",
        "        print(\"Could not load sample reconstruction for testing\")\n",
        "else:\n",
        "    print(\"No experimental directories available for testing\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
